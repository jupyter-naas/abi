{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "international-creativity",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"Google Sheets.png\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/Google%20Sheets.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-bookmark",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Google Sheets - Update leads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tags_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #googlesheets #gsheet #data #naas_drivers #growth #leads #openai #linkedin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbbbc71-6333-4a70-b371-c9b82f8b5299",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Florent Ravenel](https://www.linkedin.com/in/florent-ravenel/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naas-description",
   "metadata": {
    "papermill": {},
    "tags": [
     "description"
    ]
   },
   "source": [
    "**Description:** This notebook updates your leads database with new people that interacted with content and enrich it with ICP, company and check if they already exists inside your CRM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "input_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9e878-2148-47e3-a13d-09ba77202893",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fad521a-4a18-4dc7-b13d-98a37172715b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import naas_data_product\n",
    "import naas\n",
    "from naas_drivers import gsheet, linkedin\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date\n",
    "import openai\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec39e794-a8cd-41b8-9489-9ddb962a601c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup variables\n",
    "**Inputs**\n",
    "- `input_dir`: Input directory to retrieve file from.\n",
    "- `file_interactions`: Name of the file to be retrieved.\n",
    "- `openai_api_key`: OpenAI API Key.\n",
    "- `li_at`: Cookie used to authenticate Members and API clients.\n",
    "- `JSESSIONID`: Cookie used for Cross Site Request Forgery (CSRF) protection and URL signature validation.\n",
    "- `prompt_icp`: Prompt to be used to categorize profile by ICP.\n",
    "- `spreadsheet_url`: Google Sheets spreadsheet URL.\n",
    "- `ref_contacts_name`: Google Sheets sheet name storing contact from your CRM.\n",
    "- `leads_profiles_name`: Google Sheets sheet name storing leads profiles.\n",
    "\n",
    "**Outputs**\n",
    "- `output_dir`: Output directory to save file to.\n",
    "- `file_leads`: Output file name to save as picke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34bff6-9136-4aaf-a692-b38129b7de83",
   "metadata": {
    "papermill": {},
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "input_dir = os.path.join(naas_data_product.OUTPUTS_PATH, \"growth-engine\", date.today().isoformat())\n",
    "file_interactions = \"linkedin_interactions\"\n",
    "openai_api_key = naas.secret.get(\"OPENAI_API_KEY\")\n",
    "li_at = naas.secret.get(\"LINKEDIN_LI_AT\") or \"YOUR_LINKEDIN_LI_AT\" #example: AQFAzQN_PLPR4wAAAXc-FCKmgiMit5FLdY1af3-2\n",
    "JSESSIONID = naas.secret.get(\"LINKEDIN_JSESSIONID\") or \"YOUR_LINKEDIN_JSESSIONID\" #example: ajax:8379907400220387585\n",
    "prompt_icp = pload(os.path.join(naas_data_product.OUTPUTS_PATH, \"entity\"), \"prompt_icp\") or \"YOUR_PROMPT_ICP\"\n",
    "spreadsheet_url = naas.secret.get(\"ABI_SPREADSHEET\") or \"YOUR_GOOGLE_SPREADSHEET_URL\"\n",
    "ref_contacts_name = \"REF_CONTACTS\"\n",
    "leads_profiles_name = \"LEADS\"\n",
    "\n",
    "# Outputs\n",
    "output_dir = os.path.join(naas_data_product.OUTPUTS_PATH, \"growth-engine\", date.today().isoformat())\n",
    "file_leads = \"leads\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98ae16-e726-4f48-9c8d-8adb4ddff700",
   "metadata": {},
   "source": [
    "### Get interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322c903a-c8f5-4ea6-b249-55bf970d5f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_interactions = pload(input_dir, file_interactions)    \n",
    "print('- Interactions:', len(df_interactions))\n",
    "# df_interactions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568d91f-f088-4461-8911-95d8ad591229",
   "metadata": {},
   "source": [
    "### Extract profiles from interactions\n",
    "This function will extract unique profile from interactions database with meta data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b907024-2076-4948-9421-c90578db9cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_interactions_by_profile(\n",
    "    df_init,\n",
    "    contacts\n",
    "):\n",
    "    # Init\n",
    "    df = df_init.copy()\n",
    "    interactions = {}\n",
    "    \n",
    "    # Cleaning\n",
    "    to_select = [\n",
    "        \"PROFILE_URL\",\n",
    "        \"CONTENT_TITLE\",\n",
    "        \"CONTENT_URL\",\n",
    "        \"INTERACTION\",\n",
    "        \"INTERACTION_CONTENT\"\n",
    "    ]\n",
    "    df = df[to_select].sort_values(by=\"PROFILE_URL\").reset_index(drop=True)\n",
    "    df[\"INTERACTION_TEXT\"] = \"\"\n",
    "    df.loc[df[\"INTERACTION\"] == \"POST_REACTION\", \"INTERACTION_TEXT\"] = \"Sent '\" + df[\"INTERACTION_CONTENT\"].str.lower() + \"' reaction to '\" + df[\"CONTENT_TITLE\"].str.strip() + \"' (\" + df[\"CONTENT_URL\"] + \")\"\n",
    "    df.loc[df[\"INTERACTION\"] == \"POST_COMMENT\", \"INTERACTION_TEXT\"] = \"Comment '\" + df[\"INTERACTION_CONTENT\"].str.capitalize() + \"' on '\" + df[\"CONTENT_TITLE\"].str.strip() + \"' (\" + df[\"CONTENT_URL\"] + \")\"\n",
    "\n",
    "    # Create interactions by profile\n",
    "    for contact in contacts:\n",
    "        tmp_df = df.copy()\n",
    "        tmp_df = tmp_df[tmp_df[\"PROFILE_URL\"] == contact].reset_index(drop=True)\n",
    "        interests = \"\"\n",
    "        for row in tmp_df.itertuples():\n",
    "            interaction_text = row.INTERACTION_TEXT\n",
    "            interests = f\"{interests}{interaction_text}, \"\n",
    "        interactions[contact] = interests.strip()\n",
    "    return interactions\n",
    "\n",
    "\n",
    "\n",
    "def get_profiles_data(\n",
    "    df_init,\n",
    "):\n",
    "    # Init - Filter on profile\n",
    "    df_init = df_init[df_init[\"PROFILE_URL\"].str.contains(\"https://www.linkedin.com/in/.+\")]\n",
    "    df_score = df_init.copy()\n",
    "    df_direct = df_init.copy()\n",
    "    \n",
    "    # Get interactions score by profile\n",
    "    df_score = df_score.groupby([\"PROFILE_URL\"], as_index=False).agg({\"INTERACTION_SCORE\": \"sum\"})\n",
    "    \n",
    "    # Get profile information with last content interaction\n",
    "    to_keep = [\n",
    "        \"PROFILE_URL\",\n",
    "        \"FIRSTNAME\",\n",
    "        \"LASTNAME\",\n",
    "        \"OCCUPATION\",\n",
    "        \"PUBLIC_ID\",\n",
    "        \"PUBLISHED_DATE\",\n",
    "        \"CONTENT_URL\",\n",
    "        \"CONTENT_TITLE\"\n",
    "    ]\n",
    "    df_direct = df_direct[to_keep].drop_duplicates().drop_duplicates([\"PROFILE_URL\"])\n",
    "    \n",
    "    # Merge dfs\n",
    "    df = pd.merge(df_score, df_direct, how=\"left\")\n",
    "    \n",
    "    # Create notes from interactions\n",
    "    leads = df[\"PROFILE_URL\"].unique()  \n",
    "    df[\"NOTES\"] = df[\"PROFILE_URL\"].map(get_interactions_by_profile(df_interactions, leads))\n",
    "    \n",
    "    # Cleaning: Remove emojis from name and occupation\n",
    "    df[\"FIRSTNAME\"] = df.apply(lambda row: remove_emojis(str(row[\"FIRSTNAME\"])), axis=1)\n",
    "    df[\"LASTNAME\"] = df.apply(lambda row: remove_emojis(str(row[\"LASTNAME\"])), axis=1)\n",
    "    df[\"OCCUPATION\"] = df.apply(lambda row: remove_emojis(str(row[\"OCCUPATION\"])), axis=1)\n",
    "    df[\"FULLNAME\"] = df[\"FIRSTNAME\"] + \" \" + df[\"LASTNAME\"]\n",
    "\n",
    "    # Cleaning: Rename columns\n",
    "    to_rename = {\n",
    "        \"PUBLISHED_DATE\": \"LAST_INTERACTION_DATE\",\n",
    "        \"CONTENT_URL\": \"LAST_CONTENT_URL_INTERACTION\",\n",
    "        \"CONTENT_TITLE\": \"LAST_CONTENT_TITLE_INTERACTION\"\n",
    "    }\n",
    "    df = df.rename(columns=to_rename)\n",
    "    \n",
    "    # Cleaning: Update date format\n",
    "    df[\"LAST_INTERACTION_DATE\"] = pd.to_datetime(df[\"LAST_INTERACTION_DATE\"].str[:-5]).dt.strftime(\"%a. %d %b.\")\n",
    "    \n",
    "    # Cleaning: Sort vlaues\n",
    "    df = df.sort_values(by=[\"INTERACTION_SCORE\", \"LAST_INTERACTION_DATE\"], ascending=[False, False])\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "df_profiles = get_profiles_data(df_interactions)\n",
    "print(\"- Profiles:\", len(df_profiles))\n",
    "df_profiles.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e1f277-63d6-4036-a3d2-5d9e3ad5e36e",
   "metadata": {},
   "source": [
    "### Get existing leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0dc574-3708-4d82-9af2-a53d91fd4114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_leads = gsheet.connect(spreadsheet_url).get(sheet_name=leads_profiles_name)\n",
    "if not isinstance(df_leads, pd.DataFrame):\n",
    "    df_leads = pd.DataFrame()\n",
    "print(\"- Existing Leads:\", len(df_leads))\n",
    "# df_leads.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1781fbce-fdb1-4d60-aac9-3487b3c0bce6",
   "metadata": {},
   "source": [
    "### Create leads database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05943d97-ffc8-4d70-88d6-a09ebadc5fff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_db_leads(\n",
    "    df_profiles,\n",
    "    df_leads,\n",
    "    output_dir,\n",
    "):  \n",
    "    # Get meta data from existing leads\n",
    "    if len(df_leads) > 0:\n",
    "        to_keep = []\n",
    "        enrich_columns = [\n",
    "            \"PROFILE_URL\",\n",
    "            \"COMPANY\",\n",
    "            \"ICP\",\n",
    "            \"CRM_CONTACT\",\n",
    "        ]\n",
    "        for c in enrich_columns:\n",
    "            if c in df_leads.columns:\n",
    "                to_keep.append(c)\n",
    "        ref = df_leads[to_keep]\n",
    "    \n",
    "        # Merge to get meta data\n",
    "        df = pd.merge(df_profiles, ref, how=\"left\").fillna(\"TBD\")\n",
    "    else:\n",
    "        df = df_profiles\n",
    "\n",
    "    # Save database\n",
    "    pdump(output_dir, df, \"db_leads_init\")\n",
    "    return df.reset_index(drop=True)\n",
    "    \n",
    "db_leads = create_db_leads(df_profiles, df_leads, output_dir)\n",
    "print(\"- New database leads:\", len(db_leads))\n",
    "db_leads.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3a0a2-5a4e-4d9c-a8e0-44186bdb91f6",
   "metadata": {},
   "source": [
    "### Get contacts from CRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1dee0-31ec-4f34-b91e-624063c11aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_contacts = gsheet.connect(spreadsheet_url).get(sheet_name=ref_contacts_name)\n",
    "if not isinstance(ref_contacts, pd.DataFrame):\n",
    "    ref_contacts = pd.DataFrame()\n",
    "print(\"- CRM Contacts:\", len(ref_contacts))\n",
    "# df_contacts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d09c5-3751-4c15-b126-2322c6dce76a",
   "metadata": {},
   "source": [
    "### Enrich leads with OpenAI, LinkedIn and CRM matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c00c79-b19a-4e8b-adb7-2ecf324a8bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_icp(profile_url, occupation, icps):\n",
    "    icp = \"NA\"\n",
    "    if profile_url not in icps:\n",
    "        icp = create_chat_completion(openai_api_key, prompt_icp, occupation).replace(\"'\", \"\").replace('\"', '')\n",
    "        icps[profile_url] = icp\n",
    "    else:\n",
    "        icp = icps.get(profile_url)\n",
    "    pdump(output_dir, icps, \"icps\")\n",
    "    return icp\n",
    "\n",
    "def get_company(profile_url, occupation, companies):\n",
    "    prompt_company = \"\"\"\n",
    "    I will give you the occupation from a profile I get from LinkedIn, you will return the company you can extract from by checking the word after 'at' or '@'.\n",
    "    If you don't find it return \"NA\"\n",
    "    Don't put the results into quotes.\n",
    "    \"\"\"\n",
    "    company = \"NA\"\n",
    "    if profile_url not in companies or companies.get(profile_url) == \"TBD\":\n",
    "        company = create_chat_completion(openai_api_key, prompt_company, occupation).replace(\"'\", \"\").replace('\"', '')\n",
    "        companies[profile_url] = company\n",
    "    else:\n",
    "        company = companies.get(profile_url)\n",
    "    pdump(output_dir, companies, \"companies\")\n",
    "    return company\n",
    "\n",
    "def enrich_leads(\n",
    "    df_init,\n",
    "    ref,\n",
    "    output_dir,\n",
    "):\n",
    "    # Init\n",
    "    df = df_init.copy()\n",
    "\n",
    "    # Add ICP column and get existing ICPs\n",
    "    if not \"ICP\" in df.columns:\n",
    "        df[\"ICP\"] = \"TBD\"\n",
    "        icps = {}\n",
    "    else:\n",
    "        icps = pload(output_dir, \"icps\")\n",
    "        if icps is None: \n",
    "            icps = df[df[\"ICP\"] != \"TBD\"].set_index('PROFILE_URL')['ICP'].to_dict()\n",
    "            pdump(output_dir, icps, \"icps\")\n",
    "\n",
    "    # Add Company column and get existing companies\n",
    "    if not \"COMPANY\" in df.columns:\n",
    "        df[\"COMPANY\"] = \"TBD\"\n",
    "        companies = {}\n",
    "    else:\n",
    "        companies = pload(output_dir, \"companies\")\n",
    "        if companies is None:\n",
    "            companies = df[df[\"COMPANY\"] != \"TBD\"].set_index('PROFILE_URL')['COMPANY'].to_dict()\n",
    "            pdump(output_dir, companies, \"companies\")\n",
    "            \n",
    "    # Add CRM contact column and match if fullname exists\n",
    "    if not \"CRM_CONTACT\" in df.columns:\n",
    "        df[\"CRM_CONTACT\"] = \"TBD\"\n",
    "        crm_contacts = {}\n",
    "    else:\n",
    "        crm_contacts = pload(output_dir, \"crm_contacts\")\n",
    "        if crm_contacts is None:\n",
    "            crm_contacts = df[df[\"CRM_CONTACT\"] != \"TBD\"].set_index('PROFILE_URL')['CRM_CONTACT'].to_dict()\n",
    "            pdump(output_dir, crm_contacts, \"crm_contacts\")\n",
    "    \n",
    "    # Loop on profile\n",
    "    call_linkedin = 0\n",
    "    limit_linkedin = 30\n",
    "    df_lk = pload(input_dir, \"linkedin_top_card_profiles\")\n",
    "    if df_lk is None: \n",
    "        df_lk = pd.DataFrame()\n",
    "        \n",
    "    for row in df.itertuples():\n",
    "        index = row.Index\n",
    "        fullname = row.FULLNAME\n",
    "        occupation = row.OCCUPATION\n",
    "        profile_url = row.PROFILE_URL\n",
    "        icp = row.ICP\n",
    "        company = row.COMPANY\n",
    "        interaction_score = row.INTERACTION_SCORE\n",
    "        crm_contact = row.CRM_CONTACT\n",
    "        \n",
    "        # Update ICP and Company from OpenAI\n",
    "        if icp == \"TBD\" and company == \"TBD\" and openai_api_key != \"NA\":\n",
    "            print(f\"ðŸ¤– OpenAI - Finding ICP & Company for '{fullname}': {occupation} ...\")\n",
    "            print(profile_url)\n",
    "            if prompt_icp != \"NA\":\n",
    "                icp = get_icp(profile_url, occupation, icps)\n",
    "            company = get_company(profile_url, occupation, companies)\n",
    "            df.loc[index, \"ICP\"] = icp.strip()\n",
    "            df.loc[index, \"COMPANY\"] = company.strip()\n",
    "            print(\"- ICP:\", icp)\n",
    "            print(\"- Company:\", company)\n",
    "            print()\n",
    "            \n",
    "        # Update Company info\n",
    "        if company == \"NA\" and interaction_score >= 3 and call_linkedin < limit_linkedin:\n",
    "            print(f\"ðŸ•¸ï¸LinkedIn - Finding company for '{fullname}' (interaction score: {interaction_score}) ...\")\n",
    "            company_name = \"UNKNOWN\"\n",
    "            \n",
    "            # Get Top Card\n",
    "            try:\n",
    "                tmp_df = linkedin.connect(li_at, JSESSIONID).profile.get_top_card(profile_url)\n",
    "                time.sleep(2)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                company_name = \"ERROR_LINKEDIN_ENRICHMENT\"\n",
    "                tmp_df = pd.DataFrame()\n",
    "            \n",
    "            # Update company\n",
    "            if len(tmp_df) > 0:\n",
    "                df_lk = pd.concat([df_lk, tmp_df])\n",
    "                pdump(input_dir, df_lk, \"linkedin_top_card_profiles\")\n",
    "                if \"COMPANY_NAME\" in tmp_df.columns:\n",
    "                    company_name = tmp_df.loc[0, \"COMPANY_NAME\"]\n",
    "                    \n",
    "            print(\"- Company:\", company_name)\n",
    "            df.loc[index, \"COMPANY\"] = str(company_name).replace(\"None\", \"UNKNOWN\").replace(\"NA\", \"UNKNOWN\").strip()\n",
    "            call_linkedin += 1\n",
    "            if call_linkedin >= limit_linkedin:\n",
    "                print(\"ðŸ›‘ Call LinkedIn reached:\", limit_linkedin)\n",
    "            else:\n",
    "                print(\"- âš ï¸ LinkedIn call:\", call_linkedin)\n",
    "            print()\n",
    "            \n",
    "        # Find profile in CRM\n",
    "        if len(ref) > 0 and crm_contact == \"TBD\":\n",
    "            print(f\"ðŸ’› Sequence Matcher - Finding if '{fullname}' is in CRM ...\")\n",
    "            crm_contact = find_crm_match(\n",
    "                ref,\n",
    "                \"FULLNAME\",\n",
    "                fullname\n",
    "            )\n",
    "            df.loc[index, \"CRM_CONTACT\"] = crm_contact\n",
    "            print(\"- CRM contact:\", crm_contact)\n",
    "            print()\n",
    "            \n",
    "    # Cleaning\n",
    "    to_order = [\n",
    "        \"FULLNAME\",\n",
    "        \"OCCUPATION\",\n",
    "        \"COMPANY\",\n",
    "        \"ICP\",\n",
    "        \"CRM_CONTACT\",\n",
    "        \"INTERACTION_SCORE\",\n",
    "        \"NOTES\",\n",
    "        \"LAST_INTERACTION_DATE\",\n",
    "        \"LAST_CONTENT_TITLE_INTERACTION\",\n",
    "        \"LAST_CONTENT_URL_INTERACTION\",\n",
    "        \"FIRSTNAME\",\n",
    "        \"LASTNAME\",\n",
    "        \"PROFILE_URL\",\n",
    "        \"PUBLIC_ID\",\n",
    "    ]\n",
    "    df = df[to_order]\n",
    "    \n",
    "    # Save database\n",
    "    pdump(output_dir, df, \"db_leads_enrich\")\n",
    "    return df.reset_index(drop=True)\n",
    "    \n",
    "df_leads_update = enrich_leads(\n",
    "    db_leads,\n",
    "    ref_contacts,\n",
    "    output_dir,\n",
    ")  \n",
    "print(\"- Leads enriched:\", len(df_leads_update))\n",
    "df_leads_update.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "output_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cdf0dc-23bf-443e-a531-89019e9e7c68",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f7f07-4f37-4324-85aa-666b54904fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdump(output_dir, df_leads_update, file_leads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a2f7e5-a6d9-4863-b969-2d2f9f339fe0",
   "metadata": {},
   "source": [
    "### Send \"Leads\" to spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a498dd-a1d3-46fd-8b81-efa4df1813f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gsheet.connect(spreadsheet_url).send(data=df_leads_update, sheet_name=leads_profiles_name, append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5eb332-42ea-4dee-9090-6a7c1250e47c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "cf32ecf61a1d6fdcae3273e7e70026564087776ace44ace0a939c08a2085586f",
   "notebook_path": "Google Sheets/Google_Sheets_Send_data.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
