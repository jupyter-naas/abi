{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "international-creativity",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"Google Sheets.png\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/Google%20Sheets.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-bookmark",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Google Sheets - Update interaction database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tags_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #googlesheets #gsheet #data #naas_drivers #growth-engine #automation #picke #linkedin #interactions #comments #likes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbbbc71-6333-4a70-b371-c9b82f8b5299",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Florent Ravenel](https://www.linkedin.com/in/florent-ravenel/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naas-description",
   "metadata": {
    "papermill": {},
    "tags": [
     "description"
    ]
   },
   "source": [
    "**Description:** This notebook updates interaction database with new interactions from likes and comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "input_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9e878-2148-47e3-a13d-09ba77202893",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fad521a-4a18-4dc7-b13d-98a37172715b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from naas_drivers import gsheet\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date\n",
    "import naas_data_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec39e794-a8cd-41b8-9489-9ddb962a601c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup variables\n",
    "**Inputs**\n",
    "- `input_dir`: Input directory to retrieve file from.\n",
    "- `file_reactions`: Name of the file with reactions to be retrieved.\n",
    "- `file_comments`: Name of the file with comments to be retrieved.\n",
    "\n",
    "**Outputs**\n",
    "- `output_dir`: Output directory to save file to.\n",
    "- `output_file`: Output file name to save as picke.\n",
    "- `spreadsheet_url`: Google Sheets spreadsheet URL.\n",
    "- `sheet_name`: Google Sheets sheet name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34bff6-9136-4aaf-a692-b38129b7de83",
   "metadata": {
    "papermill": {},
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "input_dir = os.path.join(naas_data_product.OUTPUTS_PATH, \"growth-engine\", date.today().isoformat())\n",
    "file_reactions = \"linkedin_post_reactions\"\n",
    "file_comments = \"linkedin_post_comments\"\n",
    "datalake_dir = naas_data_product.OUTPUTS_PATH\n",
    "\n",
    "# Outputs\n",
    "output_dir = os.path.join(naas_data_product.OUTPUTS_PATH, \"growth-engine\", date.today().isoformat())\n",
    "output_file = \"linkedin_interactions\"\n",
    "spreadsheet_url = naas.secret.get(\"ABI_SPREADSHEET\")\n",
    "sheet_name = \"INTERACTIONS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82dbc1b-acf3-4e44-8dac-e4f631787afa",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34407369-03a1-45c4-9768-03222224612b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_init = gsheet.connect(spreadsheet_url).get(sheet_name=sheet_name)\n",
    "if not isinstance(df_init, pd.DataFrame):\n",
    "    df_init = pd.DataFrame()\n",
    "print(\"🗂️ Interactions (init):\", len(df_init))\n",
    "# df_gsheet.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568d91f-f088-4461-8911-95d8ad591229",
   "metadata": {},
   "source": [
    "### Get reactions\n",
    "We can not have a precise date of a reaction. Therefore, our approach is to initially assign the reaction date as the same date as the content's published. However, since we update our database on a daily basis, we can capture new interactions on a daily basis as well. In such cases, we assign the date of the extraction as the reaction date, allowing us to accurately track and record the timing of these interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3a425-5492-4050-88bb-5b46fa876d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get reaction files\n",
    "reactions_files = sorted(glob.glob(os.path.join(datalake_dir, \"growth-engine\", \"**\", f\"{file_reactions}.pickle\"), recursive=True))\n",
    "\n",
    "# Loop in files\n",
    "limit = (datetime.now(TIMEZONE) - timedelta(days=datetime.now(TIMEZONE).weekday() + 7)).date() # Limit date on the 2 weeks\n",
    "df_reactions = pd.DataFrame()\n",
    "posts_url = []\n",
    "for index, file in enumerate(reactions_files):\n",
    "    input_dir_r = file.split(file_reactions)[0]\n",
    "    date_dir = datetime.strptime(file.split(\"/\")[-2], \"%Y-%m-%d\").replace(tzinfo=pytz.timezone('Europe/Paris')).date()\n",
    "    if date_dir >= limit:\n",
    "        tmp_df_reactions = pload(input_dir_r, file_reactions)\n",
    "        if tmp_df_reactions is not None:\n",
    "            tmp_posts_url = tmp_df_reactions[\"POST_URL\"].unique().tolist()\n",
    "            for x in tmp_posts_url:\n",
    "                if x not in posts_url:\n",
    "                    # Histo\n",
    "                    if date_dir < date(2024, 5 , 1):\n",
    "                        tmp_df_reactions[\"DATE_REACTION\"] = pd.to_datetime(tmp_df_reactions['PUBLISHED_DATE'], format='%Y-%m-%d %H:%M:%S%z').dt.tz_convert(TIMEZONE).dt.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "                    else:\n",
    "                        tmp_df_reactions[\"DATE_REACTION\"] = tmp_df_reactions['PUBLISHED_DATE']\n",
    "                    posts_url.append(x)\n",
    "                else:\n",
    "                    tmp_df_reactions[\"DATE_REACTION\"] = pd.to_datetime(tmp_df_reactions['DATE_EXTRACT'], format='%Y-%m-%d %H:%M:%S').dt.tz_localize(pytz.timezone(\"Europe/Paris\")).dt.tz_convert(TIMEZONE).dt.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "            df_reactions = pd.concat([df_reactions, tmp_df_reactions])\n",
    "        \n",
    "if len(df_reactions) > 0:\n",
    "    df_reactions = df_reactions.drop_duplicates([\"PROFILE_URL\", \"POST_URL\"], keep=\"first\").reset_index(drop=True)\n",
    "    \n",
    "print('👍 Total Reactions:', len(df_reactions))\n",
    "df_reactions.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de21922-da06-4f65-89e1-d54a2ff1086b",
   "metadata": {},
   "source": [
    "### Get comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb75165-5195-48a9-9c71-9b648575da46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_comments = pload(input_dir, file_comments)\n",
    "print('🗨️ Total Comments:', len(df_comments))\n",
    "df_comments.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1683da4f-41e3-4e11-9c3a-bf01af8ebefe",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ec5d6-0272-4839-a21c-a4caa6f03f58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_interactions_dataset(\n",
    "    df_gsheet,\n",
    "    df_reactions,\n",
    "    df_comments,\n",
    "):\n",
    "    # Init\n",
    "    df1 = pd.DataFrame()\n",
    "    df2 = pd.DataFrame()\n",
    "    \n",
    "    if len(df_reactions) > 0:\n",
    "        # Df reactions\n",
    "        data_reaction = {\n",
    "            \"ENTITY\": df_reactions[\"ENTITY\"],\n",
    "            \"SCENARIO\": df_reactions[\"SCENARIO\"],\n",
    "            \"PLATFORM\": \"LinkedIn\",\n",
    "            \"FIRSTNAME\": df_reactions[\"FIRSTNAME\"],\n",
    "            \"LASTNAME\": df_reactions[\"LASTNAME\"],\n",
    "            \"FULLNAME\": df_reactions[\"FULLNAME\"],\n",
    "            \"OCCUPATION\": df_reactions[\"OCCUPATION\"],\n",
    "            \"INTERACTION\": \"POST_REACTION\",\n",
    "            \"INTERACTION_CONTENT\": df_reactions[\"REACTION_TYPE\"],\n",
    "            \"INTERACTION_SCORE\": 1,\n",
    "            \"PROFILE_URL\": df_reactions[\"PROFILE_URL\"],\n",
    "            \"PUBLIC_ID\": df_reactions[\"PUBLIC_ID\"],\n",
    "            \"CONTENT_TITLE\": df_reactions[\"TITLE\"],\n",
    "            \"CONTENT_URL\": df_reactions[\"POST_URL\"],\n",
    "            \"PUBLISHED_DATE\": df_reactions['PUBLISHED_DATE'],\n",
    "            \"DATE_INTERACTION\": df_reactions[\"DATE_REACTION\"],\n",
    "            \"DATE_EXTRACT\": pd.to_datetime(df_reactions['DATE_EXTRACT']).dt.tz_localize(pytz.timezone(\"Europe/Paris\")).dt.strftime(\"%Y-%m-%d %H:%M:%S%z\"),\n",
    "        }\n",
    "        df1 = pd.DataFrame(data_reaction)\n",
    "        \n",
    "    if len(df_comments) > 0:\n",
    "        # Df comments\n",
    "        data_comment = {\n",
    "            \"ENTITY\": df_comments[\"ENTITY\"],\n",
    "            \"SCENARIO\": df_comments[\"SCENARIO\"],\n",
    "            \"PLATFORM\": \"LinkedIn\",\n",
    "            \"FIRSTNAME\": df_comments[\"FIRSTNAME\"],\n",
    "            \"LASTNAME\": df_comments[\"LASTNAME\"],\n",
    "            \"FULLNAME\": df_comments[\"FULLNAME\"],\n",
    "            \"OCCUPATION\": df_comments[\"OCCUPATION\"],\n",
    "            \"INTERACTION\": \"POST_COMMENT\",\n",
    "            \"INTERACTION_CONTENT\": df_comments[\"TEXT\"],\n",
    "            \"INTERACTION_SCORE\": 3,\n",
    "            \"PROFILE_URL\": df_comments[\"PROFILE_URL\"],\n",
    "            \"PUBLIC_ID\": df_comments[\"PUBLIC_ID\"],\n",
    "            \"CONTENT_TITLE\": df_comments[\"TITLE\"],\n",
    "            \"CONTENT_URL\": df_comments[\"CONTENT_URL\"],\n",
    "            \"PUBLISHED_DATE\": df_comments['PUBLISHED_DATE'],\n",
    "            \"DATE_INTERACTION\": pd.to_datetime(df_comments['CREATED_TIME']).dt.tz_localize(pytz.timezone(\"Europe/Paris\")).dt.tz_convert(TIMEZONE).dt.strftime(\"%Y-%m-%d %H:%M:%S%z\"),\n",
    "            \"DATE_EXTRACT\": pd.to_datetime(df_comments['DATE_EXTRACT']).dt.tz_localize(pytz.timezone(\"Europe/Paris\")).dt.strftime(\"%Y-%m-%d %H:%M:%S%z\"),\n",
    "        }\n",
    "        df2 = pd.DataFrame(data_comment)\n",
    "    \n",
    "    # Concat df\n",
    "    df = pd.concat([df1, df2]).reset_index(drop=True)\n",
    "    df.insert(loc=2, column=\"DATE\", value=pd.to_datetime(df['DATE_INTERACTION'], format=\"%Y-%m-%d %H:%M:%S%z\").dt.strftime(\"%a. %d %b.\"))\n",
    "    \n",
    "    # Exclude Entity from Full name\n",
    "    if len(df) > 0:\n",
    "        entity = df.loc[0 , \"ENTITY\"]\n",
    "        df = df[df[\"FULLNAME\"] != entity]\n",
    "        \n",
    "    # Drop duplicates\n",
    "    drop_duplicates = [\n",
    "        \"ENTITY\",\n",
    "        \"SCENARIO\",\n",
    "        \"PROFILE_URL\",\n",
    "        \"INTERACTION_CONTENT\",\n",
    "        \"CONTENT_URL\"\n",
    "    ]\n",
    "    df = pd.concat([df, df_gsheet]).drop_duplicates(drop_duplicates).reset_index(drop=True)\n",
    "    df[\"ORDER\"] = pd.to_datetime(df['DATE_INTERACTION'], format=\"%Y-%m-%d %H:%M:%S%z\").dt.strftime(\"%Y%m%d%H%M%S\")\n",
    "    df[\"DATE_EXTRACT\"] = pd.to_datetime(df['DATE_EXTRACT']).dt.tz_convert(TIMEZONE).dt.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "    \n",
    "    # Sort values\n",
    "    df = df.sort_values(by=[\"ORDER\", \"FULLNAME\"], ascending=[False, True])\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "df_interactions = create_interactions_dataset(\n",
    "    df_init,\n",
    "    df_reactions,\n",
    "    df_comments,\n",
    ")\n",
    "print('🗂️ Interactions:', len(df_interactions))\n",
    "df_interactions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "output_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d3ad72-aa05-4f67-9407-bdf29f423aee",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc65a28-ed03-4fa4-b80c-6ef823639807",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdump(output_dir, df_interactions, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b11537-6391-4022-b55d-dd1f84cbe97f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Send data to Google Sheets spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e91b35-c1f8-4fe6-ae78-a2d4b79c8be7",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_check = pd.concat([df_init.astype(str), df_interactions.astype(str)]).drop_duplicates(keep=False)\n",
    "if len(df_check) > 0:\n",
    "    gsheet.connect(spreadsheet_url).send(sheet_name=sheet_name, data=df_interactions, append=False)\n",
    "else:\n",
    "    print(\"Noting to update in Google Sheets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29368ef4-de34-44bc-8d8a-346909b8ea30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "cf32ecf61a1d6fdcae3273e7e70026564087776ace44ace0a939c08a2085586f",
   "notebook_path": "Google Sheets/Google_Sheets_Send_data.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
