{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "international-creativity",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"Google Sheets.png\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/Google%20Sheets.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-bookmark",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Google Sheets - Update people database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tags_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #googlesheets #gsheet #data #naas_drivers #growth #leads #openai #linkedin #people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbbbc71-6333-4a70-b371-c9b82f8b5299",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Florent Ravenel](https://www.linkedin.com/in/florent-ravenel/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naas-description",
   "metadata": {
    "papermill": {},
    "tags": [
     "description"
    ]
   },
   "source": [
    "**Description:** This notebook updates your people database with new people that interacted with content and enrich it with ICP and company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "input_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9e878-2148-47e3-a13d-09ba77202893",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fad521a-4a18-4dc7-b13d-98a37172715b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T18:25:10.986186Z",
     "iopub.status.busy": "2024-01-08T18:25:10.985960Z",
     "iopub.status.idle": "2024-01-08T18:25:20.192020Z",
     "shell.execute_reply": "2024-01-08T18:25:20.191318Z",
     "shell.execute_reply.started": "2024-01-08T18:25:10.986130Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üï£ Your Production Timezone is Europe/Paris\n",
      "\n",
      "‚úÖ utils file '/home/ftp/abi/utils/data.ipynb' successfully loaded.\n",
      "‚úÖ utils file '/home/ftp/abi/utils/llm.ipynb' successfully loaded.\n",
      "‚úÖ utils file '/home/ftp/abi/utils/naas_chat_plugin.ipynb' successfully loaded.\n",
      "‚úÖ utils file '/home/ftp/abi/utils/naas_lab.ipynb' successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "import naas_data_product\n",
    "import naas\n",
    "from naas_drivers import gsheet, linkedin\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date\n",
    "import openai\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec39e794-a8cd-41b8-9489-9ddb962a601c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup variables\n",
    "**Inputs**\n",
    "- `input_dir`: Input directory to retrieve file from.\n",
    "- `file_interactions`: Name of the file to be retrieved.\n",
    "- `api_key`: LLM API Key.\n",
    "- `li_at`: Cookie used to authenticate Members and API clients.\n",
    "- `JSESSIONID`: Cookie used for Cross Site Request Forgery (CSRF) protection and URL signature validation.\n",
    "- `spreadsheet_url`: Google Sheets spreadsheet URL.\n",
    "- `people_sheetname`: Google Sheets sheet name storing leads profiles.\n",
    "- `prompt_seniority`: Prompt to be used to find people seniority.\n",
    "- `prompt_department`: Prompt to be used to find people department.\n",
    "- `prompt_company`: Prompt to be used to find people company.\n",
    "\n",
    "**Outputs**\n",
    "- `output_dir`: Output directory to save file to.\n",
    "- `file_people`: Output file name to save as picke.\n",
    "- `datalake_dir`: Datalake directory (outputs folder from abi project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c34bff6-9136-4aaf-a692-b38129b7de83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T18:25:20.193547Z",
     "iopub.status.busy": "2024-01-08T18:25:20.193301Z",
     "iopub.status.idle": "2024-01-08T18:25:20.708141Z",
     "shell.execute_reply": "2024-01-08T18:25:20.707284Z",
     "shell.execute_reply.started": "2024-01-08T18:25:20.193515Z"
    },
    "papermill": {},
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "input_dir = os.path.join(naas_data_product.OUTPUTS_PATH, \"growth-engine\", date.today().isoformat())\n",
    "file_interactions = \"linkedin_interactions\"\n",
    "api_key = naas.secret.get(\"OPENAI_API_KEY\")\n",
    "li_at = naas.secret.get(\"LINKEDIN_LI_AT\") or \"YOUR_LINKEDIN_LI_AT\" #example: AQFAzQN_PLPR4wAAAXc-FCKmgiMit5FLdY1af3-2\n",
    "JSESSIONID = naas.secret.get(\"LINKEDIN_JSESSIONID\") or \"YOUR_LINKEDIN_JSESSIONID\" #example: ajax:8379907400220387585\n",
    "spreadsheet_url = naas.secret.get(\"ABI_SPREADSHEET\") or \"YOUR_GOOGLE_SPREADSHEET_URL\"\n",
    "people_sheetname = \"PEOPLE\"\n",
    "prompt_seniority = \"\"\"\n",
    "Find the seniority that matches the most with the occupation extracted from a LinkedIn profile, if there is no exact match, you WON'T return a sentence or ask for more information but stricly return \"Professional/Staff\".\n",
    "Seniority definition:\n",
    "- \"Entry-Level\": Any occupation with Intern/Internship, Trainee, Junior\n",
    "- \"Professional/Staff\": [Role] Specialist, [Role] Analyst, [Role] Coordinator.\n",
    "- \"Senior Professional/Staff\": Senior [Role] Specialist, Senior [Role] Analyst.\n",
    "- \"Lead/Supervisor\": Team Lead, Supervisor.\n",
    "- \"Manager\": Manager, [Department] Manager.\n",
    "- \"Senior Manager\": Senior Manager, Director.\n",
    "- \"Executive\": Vice President, Chief [Role] Officer (CFO, CTO, etc.).\n",
    "- \"Top Executive\": President, CEO, Managing Director.\n",
    "\"\"\"\n",
    "prompt_department = \"\"\"\n",
    "Find the department that matches the most with the occupation extracted from a LinkedIn Profile, if there is no exact match, you WON'T return a sentence or ask for more information but stricly return \"Not Found\".\n",
    "Use the list below as a starting point to understand the department affiliations.\n",
    "Remember, roles can vary across industries, and some individuals may wear multiple hats in smaller companies.\n",
    "Departments: \n",
    "- \"Human Resources (HR)\": handling employee relations, benefits, recruitment, training, and workplace culture. Keywords: \"Recruiter,\" \"HR Manager,\" or \"Training Coordinator.\"\n",
    "- \"Finance\": handling company finances, budgets, payroll, taxes, financial reporting, and investment strategies. Keywords: \"Financial Analyst,\" \"Accountant,\" or \"Chief Financial Officer (CFO)\" \n",
    "- \"Marketing\": handling promotion of the business, market research, developing marketing strategies, and managing advertising. Look for titles like \"Marketing Director,\" \"Brand Manager,\" or \"Content Strategist.\"\n",
    "- \"Sales\": handling revenue generation through sales strategies, customer relationships, and managing sales teams. Titles might include \"Sales Representative,\" \"Account Executive,\" or \"Sales Manager.\"\n",
    "- \"Operations\": handling day-to-day operations, production efficiency, quality control, and supply chain management. Look for \"Operations Manager,\" \"Production Supervisor,\" or \"Supply Chain Analyst.\"\n",
    "- \"Information Technology (IT)\": managing technology infrastructure, supporting systems, ensuring cybersecurity. Titles such as \"IT Support Specialist,\" \"Systems Administrator,\" or \"Chief Information Officer (CIO)\" are indicative.\n",
    "- \"Research and Development (R&D)\": involving the development of new products or services and market research. Look for \"Research Scientist,\" \"Product Developer,\" or \"R&D Manager.\"\n",
    "- \"Customer Service\": assisting customers, maintaining satisfaction, and managing feedback. Common titles include \"Customer Service Representative,\" \"Support Technician,\" or \"Client Relations Manager.\"\n",
    "- \"Legal\": Occupations handling legal matters, compliance, contracts, and advising on legal risks. Titles like \"Corporate Lawyer,\" \"Legal Assistant,\" or \"Compliance Officer\" are relevant.\n",
    "- \"Procurement\": look for roles related to acquiring goods and services, negotiating with suppliers. Titles might include \"Procurement Officer,\" \"Purchasing Manager,\" or \"Supply Coordinator.\"\n",
    "- \"Quality Assurance (QA)\": ensuring products and services meet standards and regulations. Look for \"Quality Assurance Specialist,\" \"QA Tester,\" or \"Quality Manager.\"\n",
    "- \"Logistics and Supply Chain\": managing the flow of goods, optimizing delivery routes, and inventory. Titles such as \"Logistics Coordinator,\" \"Supply Chain Analyst,\" or \"Fleet Manager\" are common.\n",
    "- \"Public Relations (PR)\":  managing the company's public image, press releases, and media communications. Look for \"Public Relations Specialist,\" \"Communications Director,\" or \"Media Coordinator.\"\n",
    "- \"Executive Management\": high-level decision-makers setting company strategy. Titles include \"Chief Executive Officer (CEO),\" \"Managing Director,\" or \"Executive Vice President.\"\n",
    "- \"Product Management\": overseeing product development and lifecycle. Titles might be \"Product Manager,\" \"Product Owner,\" or \"Product Development Lead.\"\n",
    "- \"Strategy and Business Development\": Look for roles identifying new business opportunities and planning. Titles include \"Business Development Manager,\" \"Strategic Planner,\" or \"Growth Analyst.\"\n",
    "- \"Education\": Look for roles that try to teach or educate people.\n",
    "\"\"\"\n",
    "prompt_company = \"\"\"\n",
    "I will give you the occupation from a profile I get from LinkedIn, you will return the company you can extract from by checking the word after 'at' or '@'.\n",
    "If you don't find it return \"NA\"\n",
    "Don't put the results into quotes.\n",
    "\"\"\"\n",
    "\n",
    "# Outputs\n",
    "output_dir = os.path.join(naas_data_product.OUTPUTS_PATH, \"growth-engine\", date.today().isoformat())\n",
    "file_people = \"people\"\n",
    "datalake_dir = os.path.join(\"/\", \"home\", \"ftp\", \"abi\", \"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e1f277-63d6-4036-a3d2-5d9e3ad5e36e",
   "metadata": {},
   "source": [
    "### Get people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0dc574-3708-4d82-9af2-a53d91fd4114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T18:25:20.712582Z",
     "iopub.status.busy": "2024-01-08T18:25:20.712392Z",
     "iopub.status.idle": "2024-01-08T18:25:21.144458Z",
     "shell.execute_reply": "2024-01-08T18:25:21.143808Z",
     "shell.execute_reply.started": "2024-01-08T18:25:20.712560Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- People (init): 193\n"
     ]
    }
   ],
   "source": [
    "df_init = gsheet.connect(spreadsheet_url).get(sheet_name=people_sheetname)\n",
    "if not isinstance(df_init, pd.DataFrame):\n",
    "    df_init = pd.DataFrame()\n",
    "print(\"- People (init):\", len(df_init))\n",
    "# df_leads.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98ae16-e726-4f48-9c8d-8adb4ddff700",
   "metadata": {},
   "source": [
    "### Get interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "322c903a-c8f5-4ea6-b249-55bf970d5f8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T18:25:21.146445Z",
     "iopub.status.busy": "2024-01-08T18:25:21.145991Z",
     "iopub.status.idle": "2024-01-08T18:25:21.170312Z",
     "shell.execute_reply": "2024-01-08T18:25:21.169707Z",
     "shell.execute_reply.started": "2024-01-08T18:25:21.146411Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Interactions: 291\n"
     ]
    }
   ],
   "source": [
    "df_interactions = pload(input_dir, file_interactions)    \n",
    "print('- Interactions:', len(df_interactions))\n",
    "# df_interactions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568d91f-f088-4461-8911-95d8ad591229",
   "metadata": {},
   "source": [
    "### Extract profiles from interactions\n",
    "This function will extract unique profile from interactions database with meta data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b907024-2076-4948-9421-c90578db9cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T18:25:21.171409Z",
     "iopub.status.busy": "2024-01-08T18:25:21.171192Z",
     "iopub.status.idle": "2024-01-08T18:25:21.870824Z",
     "shell.execute_reply": "2024-01-08T18:25:21.870175Z",
     "shell.execute_reply.started": "2024-01-08T18:25:21.171387Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- People: 193\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>FIRSTNAME</th>\n",
       "      <th>LASTNAME</th>\n",
       "      <th>FULLNAME</th>\n",
       "      <th>OCCUPATION</th>\n",
       "      <th>SENIORITY</th>\n",
       "      <th>DEPARTMENT</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>INTERACTION_SCORE</th>\n",
       "      <th>MQL_DATE</th>\n",
       "      <th>SQL_DATE</th>\n",
       "      <th>LAST_INTERACTION_DATE</th>\n",
       "      <th>NOTES</th>\n",
       "      <th>PROFILE_URL</th>\n",
       "      <th>PUBLIC_ID</th>\n",
       "      <th>LAST_CONTENT_TITLE_INTERACTION</th>\n",
       "      <th>LAST_CONTENT_URL_INTERACTION</th>\n",
       "      <th>CRM_CONTACT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-12 17:30:06+0100</td>\n",
       "      <td>Vin</td>\n",
       "      <td>Vashishta</td>\n",
       "      <td>Vin Vashishta</td>\n",
       "      <td>AI Advisor | Author ‚ÄúFrom Data To Profit‚Äù | Co...</td>\n",
       "      <td>Professional/Staff</td>\n",
       "      <td>Strategy and Business Development</td>\n",
       "      <td>V Squared</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-12-12 17:30:06+0100</td>\n",
       "      <td>2024-01-06 20:32:08+0100</td>\n",
       "      <td>2024-01-06 20:32:08+0100</td>\n",
       "      <td>[Vin Vashishta sent 'like' reaction to 'Your a...</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAAADS0WQBhQQVMD...</td>\n",
       "      <td>vineetvashishta</td>\n",
       "      <td>Without efficient workflows, hiring more peopl...</td>\n",
       "      <td>https://www.linkedin.com/feed/update/urn:li:ac...</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-16 22:59:09+0100</td>\n",
       "      <td>Matteo</td>\n",
       "      <td>Castiello</td>\n",
       "      <td>Matteo Castiello</td>\n",
       "      <td>Generative AI Advisor and Researcher | Guiding...</td>\n",
       "      <td>Professional/Staff</td>\n",
       "      <td>Research and Development (R&amp;D)</td>\n",
       "      <td>33A</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-12-16 22:59:09+0100</td>\n",
       "      <td>2024-01-06 20:32:08+0100</td>\n",
       "      <td>2024-01-06 20:32:08+0100</td>\n",
       "      <td>[Matteo Castiello sent 'praise' reaction to 'I...</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAACenYg8BoVOSWA...</td>\n",
       "      <td>matteocastiello</td>\n",
       "      <td>Without efficient workflows, hiring more peopl...</td>\n",
       "      <td>https://www.linkedin.com/feed/update/urn:li:ac...</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-02 23:10:00+0100</td>\n",
       "      <td>Akmel</td>\n",
       "      <td>Syed</td>\n",
       "      <td>Akmel Syed</td>\n",
       "      <td>I help companies get started with AI | AI Cons...</td>\n",
       "      <td>Professional/Staff</td>\n",
       "      <td>Information Technology (IT)</td>\n",
       "      <td>Qlik</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-01-02 23:10:00+0100</td>\n",
       "      <td>2024-01-06 22:40:28+0100</td>\n",
       "      <td>2024-01-06 22:40:28+0100</td>\n",
       "      <td>[Akmel Syed sent 'like' reaction to 'Without e...</td>\n",
       "      <td>https://www.linkedin.com/in/ACoAAAZMWqMBrP6avP...</td>\n",
       "      <td>akmel-syed</td>\n",
       "      <td>Without efficient workflows, hiring more peopl...</td>\n",
       "      <td>https://www.linkedin.com/feed/update/urn:li:ac...</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CREATED_DATE FIRSTNAME   LASTNAME          FULLNAME  \\\n",
       "0  2023-12-12 17:30:06+0100       Vin  Vashishta     Vin Vashishta   \n",
       "1  2023-12-16 22:59:09+0100    Matteo  Castiello  Matteo Castiello   \n",
       "2  2024-01-02 23:10:00+0100     Akmel       Syed        Akmel Syed   \n",
       "\n",
       "                                          OCCUPATION           SENIORITY  \\\n",
       "0  AI Advisor | Author ‚ÄúFrom Data To Profit‚Äù | Co...  Professional/Staff   \n",
       "1  Generative AI Advisor and Researcher | Guiding...  Professional/Staff   \n",
       "2  I help companies get started with AI | AI Cons...  Professional/Staff   \n",
       "\n",
       "                          DEPARTMENT    COMPANY  INTERACTION_SCORE  \\\n",
       "0  Strategy and Business Development  V Squared                 12   \n",
       "1     Research and Development (R&D)        33A                 10   \n",
       "2        Information Technology (IT)       Qlik                  8   \n",
       "\n",
       "                   MQL_DATE                  SQL_DATE  \\\n",
       "0  2023-12-12 17:30:06+0100  2024-01-06 20:32:08+0100   \n",
       "1  2023-12-16 22:59:09+0100  2024-01-06 20:32:08+0100   \n",
       "2  2024-01-02 23:10:00+0100  2024-01-06 22:40:28+0100   \n",
       "\n",
       "      LAST_INTERACTION_DATE  \\\n",
       "0  2024-01-06 20:32:08+0100   \n",
       "1  2024-01-06 20:32:08+0100   \n",
       "2  2024-01-06 22:40:28+0100   \n",
       "\n",
       "                                               NOTES  \\\n",
       "0  [Vin Vashishta sent 'like' reaction to 'Your a...   \n",
       "1  [Matteo Castiello sent 'praise' reaction to 'I...   \n",
       "2  [Akmel Syed sent 'like' reaction to 'Without e...   \n",
       "\n",
       "                                         PROFILE_URL        PUBLIC_ID  \\\n",
       "0  https://www.linkedin.com/in/ACoAAADS0WQBhQQVMD...  vineetvashishta   \n",
       "1  https://www.linkedin.com/in/ACoAACenYg8BoVOSWA...  matteocastiello   \n",
       "2  https://www.linkedin.com/in/ACoAAAZMWqMBrP6avP...       akmel-syed   \n",
       "\n",
       "                      LAST_CONTENT_TITLE_INTERACTION  \\\n",
       "0  Without efficient workflows, hiring more peopl...   \n",
       "1  Without efficient workflows, hiring more peopl...   \n",
       "2  Without efficient workflows, hiring more peopl...   \n",
       "\n",
       "                        LAST_CONTENT_URL_INTERACTION CRM_CONTACT_ID  \n",
       "0  https://www.linkedin.com/feed/update/urn:li:ac...            TBD  \n",
       "1  https://www.linkedin.com/feed/update/urn:li:ac...            TBD  \n",
       "2  https://www.linkedin.com/feed/update/urn:li:ac...            TBD  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_date_interaction(\n",
    "    df_init,\n",
    "    col_date,\n",
    "    new_col_date,\n",
    "):\n",
    "    # Init\n",
    "    df = df_init.copy()\n",
    "    df = df.sort_values(col_date, ascending=True)\n",
    "    \n",
    "    # Drop duplicates\n",
    "    to_keep = [\n",
    "        \"PROFILE_URL\",\n",
    "        col_date,\n",
    "    ]\n",
    "    df = df[to_keep].drop_duplicates([\"PROFILE_URL\"], keep=\"first\").rename(columns={col_date: new_col_date})\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def get_interactions_by_profile(\n",
    "    df_init,\n",
    "    contacts\n",
    "):\n",
    "    # Init\n",
    "    df = df_init.copy()\n",
    "    interactions = {}\n",
    "    \n",
    "    # Cleaning\n",
    "    to_select = [\n",
    "        \"PROFILE_URL\",\n",
    "        \"FULLNAME\",\n",
    "        \"CONTENT_TITLE\",\n",
    "        \"CONTENT_URL\",\n",
    "        \"INTERACTION\",\n",
    "        \"INTERACTION_CONTENT\",\n",
    "        \"DATE_INTERACTION\"\n",
    "    ]\n",
    "    df = df[to_select].sort_values(by=\"PROFILE_URL\").reset_index(drop=True)\n",
    "    df[\"INTERACTION_TEXT\"] = \"\"\n",
    "    df.loc[df[\"INTERACTION\"] == \"POST_REACTION\", \"INTERACTION_TEXT\"] = df[\"FULLNAME\"]  + \" sent '\" + df[\"INTERACTION_CONTENT\"].str.lower() + \"' reaction to '\" + df[\"CONTENT_TITLE\"].str.strip() + \"' (\" + df[\"CONTENT_URL\"] + \") on \" + df[\"DATE_INTERACTION\"].astype(str)\n",
    "    df.loc[df[\"INTERACTION\"] == \"POST_COMMENT\", \"INTERACTION_TEXT\"] = df[\"FULLNAME\"]  + \" commented '\" + df[\"INTERACTION_CONTENT\"].str.capitalize() + \"' on '\" + df[\"CONTENT_TITLE\"].str.strip() + \"' (\" + df[\"CONTENT_URL\"] + \") on \" + df[\"DATE_INTERACTION\"].astype(str)\n",
    "\n",
    "    # Create interactions by profile\n",
    "    for contact in contacts:\n",
    "        tmp_df = df.copy()\n",
    "        tmp_df = tmp_df[tmp_df[\"PROFILE_URL\"] == contact].reset_index(drop=True)\n",
    "        interests = []\n",
    "        for row in tmp_df.itertuples():\n",
    "            interaction_text = row.INTERACTION_TEXT\n",
    "            interests.append(interaction_text)\n",
    "        interactions[contact] = interests\n",
    "    return interactions\n",
    "\n",
    "def create_db_people(\n",
    "    df_init,\n",
    "    df_interactions,\n",
    "    output_dir,\n",
    "):\n",
    "    # Init - Filter on profile\n",
    "    df_people = df_interactions[df_interactions[\"PROFILE_URL\"].str.contains(\"https://www.linkedin.com/in/.+\")]\n",
    "    df_direct = df_people.copy()\n",
    "    df_score = df_people.copy()\n",
    "    \n",
    "    # Get first interaction -> Created date AND MQL date\n",
    "    df_created = get_date_interaction(\n",
    "        df_people,\n",
    "        \"DATE_INTERACTION\",\n",
    "        \"CREATED_DATE\",\n",
    "    )\n",
    "    df_created[\"MQL_DATE\"] = df_created[\"CREATED_DATE\"]\n",
    "    \n",
    "    # Get profile information with last content interaction -> Last interaction date\n",
    "    to_keep = [\n",
    "        \"PROFILE_URL\",\n",
    "        \"FIRSTNAME\",\n",
    "        \"LASTNAME\",\n",
    "        \"OCCUPATION\",\n",
    "        \"PUBLIC_ID\",\n",
    "        \"DATE_INTERACTION\",\n",
    "        \"CONTENT_URL\",\n",
    "        \"CONTENT_TITLE\"\n",
    "    ]\n",
    "    df_direct = df_direct[to_keep].drop_duplicates([\"PROFILE_URL\"])\n",
    "   \n",
    "    # Get interactions score by profile\n",
    "    df_score = df_score.groupby([\"PROFILE_URL\"], as_index=False).agg({\"INTERACTION_SCORE\": \"sum\"})\n",
    "    \n",
    "    # Merge dfs\n",
    "    df = pd.merge(df_created, df_direct, how=\"left\").fillna(\"NA\")\n",
    "    df = pd.merge(df, df_score, how=\"left\")\n",
    "    \n",
    "    # Get more than 3 interactions date -> SQL date\n",
    "    df_sql = get_date_interaction(\n",
    "        df[df[\"INTERACTION_SCORE\"] >= 3],\n",
    "        \"DATE_INTERACTION\",\n",
    "        \"SQL_DATE\",\n",
    "    )\n",
    "    \n",
    "    # Merge dfs and cleaning: Rename columns\n",
    "    to_rename = {\n",
    "        \"DATE_INTERACTION\": \"LAST_INTERACTION_DATE\",\n",
    "        \"CONTENT_URL\": \"LAST_CONTENT_URL_INTERACTION\",\n",
    "        \"CONTENT_TITLE\": \"LAST_CONTENT_TITLE_INTERACTION\"\n",
    "    }\n",
    "    df = pd.merge(df, df_sql, how=\"left\").rename(columns=to_rename).fillna(\"NA\")\n",
    "\n",
    "    # Cleaning: Remove emojis from name and occupation\n",
    "    df[\"FIRSTNAME\"] = df.apply(lambda row: remove_emojis(str(row[\"FIRSTNAME\"])), axis=1)\n",
    "    df[\"LASTNAME\"] = df.apply(lambda row: remove_emojis(str(row[\"LASTNAME\"])), axis=1)\n",
    "    df[\"OCCUPATION\"] = df.apply(lambda row: remove_emojis(str(row[\"OCCUPATION\"])), axis=1)\n",
    "    df[\"FULLNAME\"] = df[\"FIRSTNAME\"] + \" \" + df[\"LASTNAME\"]\n",
    "    \n",
    "    # Create notes from interactions\n",
    "    leads = df[\"PROFILE_URL\"].unique()  \n",
    "    df[\"NOTES\"] = df[\"PROFILE_URL\"].map(get_interactions_by_profile(df_people, leads))\n",
    "    \n",
    "    # Cleaning: Sort values\n",
    "    df = df.sort_values(by=[\"INTERACTION_SCORE\", \"LAST_INTERACTION_DATE\"], ascending=[False, False])\n",
    "    \n",
    "    # Get meta data from existing people\n",
    "    col_ref = [\n",
    "        \"PROFILE_URL\",\n",
    "        \"COMPANY\",\n",
    "        \"SENIORITY\",\n",
    "        \"DEPARTMENT\",\n",
    "        \"CRM_CONTACT_ID\",\n",
    "    ]\n",
    "    for c in col_ref:\n",
    "        # If columns does not exist, init value to be determined (TBD)\n",
    "        if not c in df_init.columns:\n",
    "            df_init[c] = \"TBD\"\n",
    "    ref = df_init[col_ref]\n",
    "\n",
    "    # Merge to get meta data\n",
    "    df = pd.merge(df, ref, how=\"left\").fillna(\"TBD\")\n",
    "        \n",
    "    # Cleaning\n",
    "    to_order = [\n",
    "        \"CREATED_DATE\",\n",
    "        \"FIRSTNAME\",\n",
    "        \"LASTNAME\",\n",
    "        \"FULLNAME\",\n",
    "        \"OCCUPATION\",\n",
    "        \"SENIORITY\",\n",
    "        \"DEPARTMENT\",\n",
    "        \"COMPANY\",\n",
    "        \"INTERACTION_SCORE\",\n",
    "        \"MQL_DATE\",\n",
    "        \"SQL_DATE\",\n",
    "        \"LAST_INTERACTION_DATE\",\n",
    "        \"NOTES\",\n",
    "        \"PROFILE_URL\",\n",
    "        \"PUBLIC_ID\",\n",
    "        \"LAST_CONTENT_TITLE_INTERACTION\",\n",
    "        \"LAST_CONTENT_URL_INTERACTION\",\n",
    "        \"CRM_CONTACT_ID\"\n",
    "    ]\n",
    "    df = df[to_order]\n",
    "\n",
    "    # Save database\n",
    "    pdump(output_dir, df, \"people_init\")\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "db_people = create_db_people(\n",
    "    df_init,\n",
    "    df_interactions,  \n",
    "    output_dir,\n",
    ")\n",
    "print(\"- People:\", len(db_people))\n",
    "db_people.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d09c5-3751-4c15-b126-2322c6dce76a",
   "metadata": {},
   "source": [
    "### Enrich people with company, seniority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a78b4da-d843-4283-8884-39c4560d0c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T18:25:21.872283Z",
     "iopub.status.busy": "2024-01-08T18:25:21.871900Z",
     "iopub.status.idle": "2024-01-08T18:25:21.913614Z",
     "shell.execute_reply": "2024-01-08T18:25:21.913015Z",
     "shell.execute_reply.started": "2024-01-08T18:25:21.872247Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def enrich_from_occupation(\n",
    "    occupation,\n",
    "    key,\n",
    "    keys,\n",
    "    api_key,\n",
    "    prompt,\n",
    "    file,\n",
    "    output_dir,\n",
    "):\n",
    "    result = \"NA\"\n",
    "    if key not in keys:\n",
    "        result = create_chat_completion(api_key, prompt, occupation).replace(\"'\", \"\").replace('\"', '')\n",
    "        keys[key] = result\n",
    "    else:\n",
    "        result = keys.get(key)\n",
    "    pdump(output_dir, keys, file)\n",
    "    return result\n",
    "\n",
    "def get_dict(\n",
    "    df,\n",
    "    column_name,\n",
    "    key,\n",
    "    file,\n",
    "    output_dir\n",
    "):\n",
    "    data = {}\n",
    "    if column_name in df.columns:\n",
    "        data = pload(output_dir, file)\n",
    "        if data is None: \n",
    "            data = df[~df[column_name].isin([\"TBD\", \"NA\"])].set_index(key)[column_name].to_dict()\n",
    "            pdump(output_dir, data, file)\n",
    "    return data\n",
    "\n",
    "def enrich_people(\n",
    "    df_init,\n",
    "    prompt_seniority,\n",
    "    prompt_department,\n",
    "    prompt_company,\n",
    "    output_dir,\n",
    "    datalake_dir,\n",
    "    limit_linkedin=30\n",
    "):\n",
    "    # Init\n",
    "    df = df_init.copy()\n",
    "\n",
    "    # Get people seniority\n",
    "    people_seniority = get_dict(df, \"SENIORITY\", \"PROFILE_URL\", \"people_seniority\", output_dir)\n",
    "    \n",
    "    # Get people department\n",
    "    people_department = get_dict(df, \"DEPARTMENT\", \"PROFILE_URL\", \"people_department\", output_dir)\n",
    "\n",
    "    # Get companies\n",
    "    people_companies = get_dict(df, \"COMPANY\", \"PROFILE_URL\", \"people_companies\", output_dir)\n",
    "    \n",
    "    # Loop on profile\n",
    "    call_linkedin = 0    \n",
    "    for row in df.itertuples():\n",
    "        index = row.Index\n",
    "        fullname = row.FULLNAME\n",
    "        occupation = row.OCCUPATION\n",
    "        profile_url = row.PROFILE_URL\n",
    "        seniority = row.SENIORITY\n",
    "        department = row.DEPARTMENT\n",
    "        company = row.COMPANY\n",
    "        interaction_score = row.INTERACTION_SCORE\n",
    "        \n",
    "        # Update ICP and Company from OpenAI\n",
    "        if seniority == \"TBD\" or department == \"TBD\" or company == \"TBD\" and api_key != \"NA\":\n",
    "            print(f\"ü§ñ Finding seniority, departement & company for '{fullname}' ({profile_url}) from occupation: {occupation}\")\n",
    "            seniority = enrich_from_occupation(\n",
    "                occupation,\n",
    "                profile_url,\n",
    "                people_seniority,\n",
    "                api_key,\n",
    "                prompt_seniority,\n",
    "                \"people_seniority\",\n",
    "                output_dir\n",
    "            )\n",
    "            department = enrich_from_occupation(\n",
    "                occupation,\n",
    "                profile_url,\n",
    "                people_department,\n",
    "                api_key,\n",
    "                prompt_department,\n",
    "                \"people_department\",\n",
    "                output_dir\n",
    "            )\n",
    "            company = enrich_from_occupation(\n",
    "                occupation,\n",
    "                profile_url,\n",
    "                people_companies,\n",
    "                api_key,\n",
    "                prompt_company,\n",
    "                \"people_companies\",\n",
    "                output_dir\n",
    "            )\n",
    "            df.loc[index, \"SENIORITY\"] = seniority.strip()\n",
    "            df.loc[index, \"DEPARTMENT\"] = department.strip()\n",
    "            df.loc[index, \"COMPANY\"] = company.strip()\n",
    "            print(\"- Seniority:\", seniority)\n",
    "            print(\"- Department:\", department)\n",
    "            print(\"- Company:\", company)\n",
    "            print()\n",
    "            \n",
    "        # Update Company info\n",
    "        if company == \"NA\" and interaction_score >= 3 and call_linkedin < limit_linkedin:\n",
    "            print(f\"üï∏Ô∏è Finding LinkedIn company for '{fullname}' ({profile_url}) (interaction score: {interaction_score})\")\n",
    "            company_name = \"Not Found\"\n",
    "            linkedin_dir = os.path.join(datalake_dir, \"datalake\", \"linkedin\", \"profiles\")\n",
    "            linkedin_id = profile_url.split(\"/\")[-1]\n",
    "            tmp_df = pload(linkedin_dir, f\"{linkedin_id}_linkedin_top_card\")\n",
    "            if tmp_df is None:\n",
    "                # Get Top Card\n",
    "                try:\n",
    "                    tmp_df = linkedin.connect(li_at, JSESSIONID).profile.get_top_card(profile_url)\n",
    "                    pdump(linkedin_dir, tmp_df, f\"{linkedin_id}_linkedin_top_card\")\n",
    "                    time.sleep(2)\n",
    "                    call_linkedin += 1\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    company_name = \"ERROR_LINKEDIN_ENRICHMENT\"\n",
    "                    tmp_df = pd.DataFrame()\n",
    "            if len(tmp_df) > 0:\n",
    "                company_name = tmp_df.loc[0, \"COMPANY_NAME\"]\n",
    "            df.loc[index, \"COMPANY\"] = str(company_name).replace(\"None\", \"UNKNOWN\").replace(\"NA\", \"UNKNOWN\").strip()\n",
    "            print(\"- Company:\", company_name)\n",
    "            if call_linkedin >= limit_linkedin:\n",
    "                print(\"üõë Call LinkedIn reached:\", limit_linkedin)\n",
    "            else:\n",
    "                print(\"- ‚ö†Ô∏è LinkedIn call:\", call_linkedin)\n",
    "            print()\n",
    "    return df.reset_index(drop=True)\n",
    "    \n",
    "df_people = enrich_people(\n",
    "    db_people,\n",
    "    prompt_seniority,\n",
    "    prompt_department,\n",
    "    prompt_company,\n",
    "    output_dir,\n",
    "    datalake_dir,\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "output_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cdf0dc-23bf-443e-a531-89019e9e7c68",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617f7f07-4f37-4324-85aa-666b54904fb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T18:25:21.914898Z",
     "iopub.status.busy": "2024-01-08T18:25:21.914652Z",
     "iopub.status.idle": "2024-01-08T18:25:22.089913Z",
     "shell.execute_reply": "2024-01-08T18:25:22.089326Z",
     "shell.execute_reply.started": "2024-01-08T18:25:21.914868Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdump(output_dir, df_people, file_people)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a2f7e5-a6d9-4863-b969-2d2f9f339fe0",
   "metadata": {},
   "source": [
    "### Send \"People\" to spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a498dd-a1d3-46fd-8b81-efa4df1813f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T18:25:22.091820Z",
     "iopub.status.busy": "2024-01-08T18:25:22.091571Z",
     "iopub.status.idle": "2024-01-08T18:25:22.121984Z",
     "shell.execute_reply": "2024-01-08T18:25:22.121353Z",
     "shell.execute_reply.started": "2024-01-08T18:25:22.091789Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noting to update in Google Sheets!\n"
     ]
    }
   ],
   "source": [
    "df_check = pd.concat([df_init.astype(str), df_people.astype(str)]).drop_duplicates(keep=False)\n",
    "if len(df_check) > 0:\n",
    "    gsheet.connect(spreadsheet_url).send(data=df_people, sheet_name=people_sheetname, append=False)\n",
    "else:\n",
    "    print(\"Noting to update in Google Sheets!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5eb332-42ea-4dee-9090-6a7c1250e47c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "cf32ecf61a1d6fdcae3273e7e70026564087776ace44ace0a939c08a2085586f",
   "notebook_path": "Google Sheets/Google_Sheets_Send_data.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
