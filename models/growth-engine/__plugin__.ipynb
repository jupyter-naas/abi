{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ffb6d3-d99a-410e-9d06-ba9d8bef13a7",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"Naas.png\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/Naas.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b2c509-2c29-49e8-af91-4f3f1e386da3",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Growth plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77fe283-4edd-42d3-a909-8e207d4b842f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #naaschatplugin #naas #naas_driver #chat #plugin #ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f2d91-c886-4e36-8265-b09d06bb1c7f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Florent Ravenel](https://www.linkedin.com/in/florent-ravenel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214749fe-7f0b-4755-b7ea-1d200c234cc6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Description:** This notebook creates a Naas Chat plugin with commands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff349c8-2816-4ae4-9229-027c068eeb51",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80266a9e-fe54-4f3e-aeb2-01483bbc53f9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc038b10-2679-42bc-909e-09a298339df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T15:52:25.191622Z",
     "iopub.status.busy": "2024-01-17T15:52:25.191361Z",
     "iopub.status.idle": "2024-01-17T15:52:44.696466Z",
     "shell.execute_reply": "2024-01-17T15:52:44.695477Z",
     "shell.execute_reply.started": "2024-01-17T15:52:25.191545Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ utils file '/home/ftp/abi/utils/data.ipynb' successfully loaded.\n",
      "✅ utils file '/home/ftp/abi/utils/llm.ipynb' successfully loaded.\n",
      "✅ utils file '/home/ftp/abi/utils/naas_chat_plugin.ipynb' successfully loaded.\n",
      "✅ utils file '/home/ftp/abi/utils/naas_lab.ipynb' successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "import naas\n",
    "from naas_drivers import naas_chat_plugin, gsheet\n",
    "import naas_data_product\n",
    "from IPython.display import Markdown\n",
    "from datetime import date, timedelta\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930da4d-39a2-424e-8808-77fd0a3829bf",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup variables\n",
    "**Mandatory**\n",
    "- `entity_dir`: This variable represents the entity directory.\n",
    "- `input_dir`: Input directory to retrieve file from.\n",
    "- `file_growth`: Name of the file to be retrieved.\n",
    "- `spreadsheet_url`: Google Sheets spreadsheet URL.\n",
    "- `sheet_name`: Google Sheets sheet name.\n",
    "- `name`: The name of the plugin.\n",
    "- `model`: This variable holds the openai model.\n",
    "- `temperature`: This variable holds the temperate value.\n",
    "- `description`: This variable holds a string that describes the plugin.\n",
    "- `avatar`: This variable holds a URL to an image to be displayed in your plugin as avatar.\n",
    "- `model_dir`: This variable holds a relative path to the directory where input notebooks with commands will be stored.\n",
    "\n",
    "**Optional**\n",
    "- `output_dir`: This variable holds a relative path to the directory where output files will be stored. \n",
    "- `output_path`: This variable holds the full path of the plugin.\n",
    "- `entity_name`: This variable holds the entity name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cf9bd9b-ce83-45a5-ab0f-15c978458b42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T15:52:44.698224Z",
     "iopub.status.busy": "2024-01-17T15:52:44.697983Z",
     "iopub.status.idle": "2024-01-17T15:52:44.730112Z",
     "shell.execute_reply": "2024-01-17T15:52:44.729462Z",
     "shell.execute_reply.started": "2024-01-17T15:52:44.698194Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "entity_dir = pload(os.path.join(naas_data_product.OUTPUTS_PATH, \"entities\", \"0\"), \"entity_dir\")\n",
    "input_dir = os.path.join(entity_dir, \"growth-engine\", date.today().isoformat())\n",
    "file_growth = \"growth\"\n",
    "spreadsheet_url = pload(os.path.join(naas_data_product.OUTPUTS_PATH, \"entities\", \"0\"), \"abi_spreadsheet\") or \"\"\n",
    "sheet_name = \"GROWTH\"\n",
    "name = \"🚀 Growth Assistant\"\n",
    "model = \"gpt-4-1106-preview\"\n",
    "temperature = 0.5\n",
    "description = \"Track your growth performance, understand your audience with cohorts analysis and meet your new marketing qualified leads.\"\n",
    "avatar = \"\"\n",
    "model_dir = os.path.join(naas_data_product.ROOT_PATH, \"models\", \"growth-engine\")\n",
    "\n",
    "# Outputs\n",
    "output_dir = os.path.join(entity_dir, \"plugins\")\n",
    "os.makedirs(output_dir, exist_ok=True) # Create dirs\n",
    "output_path = os.path.join(output_dir, f\"{name.lower().replace(' ', '_')}.json\")\n",
    "entity_name = pload(os.path.join(naas_data_product.OUTPUTS_PATH, \"entities\", \"0\"), \"entity_name\") or \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9070993a-eec9-4f78-a7f9-2e18c743a20d",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e20374-17f3-4642-91d2-24ae8741f0d1",
   "metadata": {},
   "source": [
    "### Get assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c534f4-7235-46b0-a5a8-dc2c28e6a181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T15:52:44.733009Z",
     "iopub.status.busy": "2024-01-17T15:52:44.732805Z",
     "iopub.status.idle": "2024-01-17T15:52:45.073449Z",
     "shell.execute_reply": "2024-01-17T15:52:45.072737Z",
     "shell.execute_reply.started": "2024-01-17T15:52:44.732987Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Image URL: https://public.naas.ai/ZmxvcmVudC00MG5hYXMtMkVhaQ==/asset/64f08a826b807c3c18aea1e8db60be704fef46ef5b47b520afbe920289ee.png\n",
      "- Image HTML: https://public.naas.ai/ZmxvcmVudC00MG5hYXMtMkVhaQ==/asset/413c4d1814f77c538d2f2c70781991839566c680ad7abee421c3557fabc3\n"
     ]
    }
   ],
   "source": [
    "image_url = get_image_asset(input_dir, \"growth_trend.png\")\n",
    "print(\"- Image URL:\", image_url)\n",
    "\n",
    "image_html = get_image_asset(input_dir, \"growth_trend.html\")\n",
    "print(\"- Image HTML:\", image_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b19ea41-fa98-4f6f-a1d7-6511919f039c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get data to be sent to prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a6d8bd-7de9-4e9e-99f9-2bdc69eb8da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T11:43:59.095488Z",
     "iopub.status.busy": "2023-12-23T11:43:59.095256Z",
     "iopub.status.idle": "2023-12-23T11:43:59.098204Z",
     "shell.execute_reply": "2023-12-23T11:43:59.097564Z",
     "shell.execute_reply.started": "2023-12-23T11:43:59.095465Z"
    },
    "tags": []
   },
   "source": [
    "#### Get content published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6cef72-fe53-4642-ad8a-b9a9e8811a12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T15:52:45.075093Z",
     "iopub.status.busy": "2024-01-17T15:52:45.074599Z",
     "iopub.status.idle": "2024-01-17T15:52:45.473304Z",
     "shell.execute_reply": "2024-01-17T15:52:45.472183Z",
     "shell.execute_reply.started": "2024-01-17T15:52:45.075060Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Post tokens: 757\n"
     ]
    }
   ],
   "source": [
    "# Get content published\n",
    "content_dir = input_dir.replace(\"growth-engine\", \"content-engine\")\n",
    "data_content = pload(content_dir, \"content\")\n",
    "if data_content is None:\n",
    "    data_content = gsheet.connect(spreadsheet_url).get(sheet_name=\"CONTENT\")\n",
    "if isinstance(data_content, pd.DataFrame):\n",
    "    df_content = data_content.copy()\n",
    "    \n",
    "if len(df_content) > 0:\n",
    "    df_content = df_content[(df_content[\"ENTITY\"] == entity_name) & (df_content[\"SCENARIO\"].isin([TW, LW]))]\n",
    "    df_content = df_content[[\"TITLE\", \"CONTENT_URL\", \"DATE\"]]\n",
    "\n",
    "# Transform df to string\n",
    "post_data = df_content.to_string()\n",
    "\n",
    "# Count tokens\n",
    "post_tokens = naas_chat_plugin.num_tokens_from_string(post_data)\n",
    "print(f\"- Post tokens: {post_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be6d57-9b38-4dbc-95db-89a6fb3aa8d1",
   "metadata": {},
   "source": [
    "#### Get leads generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4c5177b-2750-462a-9b60-8643d8db4531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T15:52:45.474669Z",
     "iopub.status.busy": "2024-01-17T15:52:45.474417Z",
     "iopub.status.idle": "2024-01-17T15:52:56.430689Z",
     "shell.execute_reply": "2024-01-17T15:52:56.429957Z",
     "shell.execute_reply.started": "2024-01-17T15:52:45.474638Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ System prompt tokens count OK: 323 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 585 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 843 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 1072 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 1273 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 1542 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 1760 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 1979 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 2206 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 2356 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 2513 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 2690 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 2833 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 2971 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 3109 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 3271 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 3435 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 3583 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 3745 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 3908 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 4050 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 4203 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 4359 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 4544 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 4694 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 4820 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 4954 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 5075 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 5238 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 5386 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 6323 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 6954 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 7696 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 8253 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 8898 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 9348 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 9911 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 10251 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 10890 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 11442 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 12006 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 12504 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 12845 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 13109 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 13444 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 13759 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 14018 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 14268 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 14747 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 14959 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 15235 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 15485 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 15680 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 16032 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 16221 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 16530 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 16756 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 17011 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 17288 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 17590 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 17870 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 18069 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 18277 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 18543 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 18740 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 18931 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 19148 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 19427 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 19772 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 20059 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 20356 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 20626 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 20942 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 21097 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 21400 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 21711 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 21875 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 22093 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 22478 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 22650 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 22774 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 22901 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 23076 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 23373 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 23585 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 23766 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 23882 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 24067 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 24290 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 24550 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 24728 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 24916 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 25110 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 25316 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 25527 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 25734 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 25949 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 26125 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 26342 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 26456 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 26570 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 26680 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 26797 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 26929 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 27060 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 27194 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 27313 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 27431 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 27560 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 27677 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 27806 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 27923 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 28044 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 28163 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 28436 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 28554 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 28698 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 28819 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 28934 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 29053 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 29174 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 29299 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 29441 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 29565 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 29679 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 29798 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 29918 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 30037 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 30153 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 30309 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 30433 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 30549 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 30696 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 30810 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 30938 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 31074 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 31209 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 31342 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 31477 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 31616 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 31742 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 31874 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 32010 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 32156 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 32289 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 32426 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 32558 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 32650 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 32782 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 32905 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 33052 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 33245 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 33386 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 33512 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 33633 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 33760 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 33874 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 33991 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 34116 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 34235 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 34350 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 34474 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 34590 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 34704 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 34838 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 34958 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 35074 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 35194 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 35311 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 35444 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 35569 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 35683 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 35820 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 35938 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 36048 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 36153 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 36302 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 36418 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 36554 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 36699 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 36833 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 36984 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 37169 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 37296 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 37416 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 37542 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 37670 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 37790 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 37913 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 38039 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 38153 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 38283 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 38422 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 38553 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 38693 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 38810 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 38929 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 39067 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 39195 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 39311 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 39465 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 39576 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 39685 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 39802 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 39919 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 40037 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 40177 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 40311 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 40433 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 40576 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 40697 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 40816 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 40948 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 41064 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 41192 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 41340 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 41454 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 41571 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 41687 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 41804 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 41968 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 42099 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 42220 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 42342 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 42453 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 42573 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 42692 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 42831 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 42974 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 43096 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 43219 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 43344 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 43477 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 43603 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 43723 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 43837 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 43958 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 44101 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 44239 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 44348 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 44478 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 44591 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 44747 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 44863 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 44985 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 45097 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 45212 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 45371 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 45521 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 45632 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 45760 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 45885 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 46032 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 46117 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 46250 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 46371 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 46515 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 46642 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 46757 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 46869 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 46991 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 47114 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 47224 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 47351 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 47468 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 47608 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 47748 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 47866 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 48042 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 48176 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 48297 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 48431 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 48549 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 48668 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 48804 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 48919 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 49034 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 49167 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 49306 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 49433 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 49593 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 49728 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 49861 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 49981 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 50106 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 50220 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 50339 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 50460 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 50576 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 50715 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 50838 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 51001 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 51130 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 51246 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 51377 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 51495 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 51618 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 51743 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 51860 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 51982 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 52108 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 52228 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 52347 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 52469 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 52594 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 52706 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 52822 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 52960 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 53078 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 53206 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 53341 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 53499 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 53630 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 53763 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 53887 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 54005 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 54152 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 54293 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 54416 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 54540 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 54671 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 54800 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 54932 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 55057 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 55197 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 55335 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 55493 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 55642 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 55760 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 55871 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 55995 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 56105 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 56219 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 56363 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 56489 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 56608 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 56726 (limit: 45% -> 57600)\n",
      "✅ System prompt tokens count OK: 56867 (limit: 45% -> 57600)\n",
      "\n",
      "- Leads: 507\n",
      "- New Leads: 9\n",
      "- Growth data: 338\n"
     ]
    }
   ],
   "source": [
    "# Init\n",
    "prompt_data = []\n",
    "total_leads = 0\n",
    "new_leads = 0\n",
    "\n",
    "# Load data from pickle\n",
    "data = pload(input_dir, file_growth)    \n",
    "if data is None:\n",
    "    data = gsheet.connect(spreadsheet_url).get(sheet_name=sheet_name)\n",
    "if isinstance(data, pd.DataFrame):\n",
    "    df = data.copy()\n",
    "\n",
    "# Filter on this week and last week\n",
    "if len(df) > 0:\n",
    "    df = df[(df[\"ENTITY\"] == entity_name) & (df[\"SCENARIO\"].isin([TW, LW]))]\n",
    "\n",
    "    # Get data\n",
    "    total_leads = len(df)\n",
    "    new_leads = len(df[(df[\"COHORT\"] == \"NEW\")])\n",
    "\n",
    "    # Filter to not exceed context windowns\n",
    "    prompt_data = []\n",
    "    limit = 0.45\n",
    "    for row in df.itertuples():\n",
    "        fullname = row.FULLNAME\n",
    "        profile_url = row.PROFILE_URL\n",
    "        occupation = row.OCCUPATION\n",
    "        last_interaction_date = row.LAST_INTERACTION_DATE\n",
    "        interactions = row.INTERACTIONS\n",
    "        string_message = f\"{fullname} - '{occupation}' ({profile_url}) interactions: {interactions}\"\n",
    "        prompt_data.append(string_message)\n",
    "        prompt_tokens, max_tokens = naas_chat_plugin.check_tokens(\n",
    "            prompt=\" ,\".join(prompt_data),\n",
    "            model=model,\n",
    "            limit=limit,\n",
    "        )\n",
    "        if prompt_tokens + post_tokens > max_tokens * limit:\n",
    "            break\n",
    "            \n",
    "print()\n",
    "print(f\"- Leads: {total_leads}\")\n",
    "print(f\"- New Leads: {new_leads}\")\n",
    "print(f\"- Growth data: {len(prompt_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266b78a-4af9-4b6f-b739-3b84f4165c25",
   "metadata": {},
   "source": [
    "### Create system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee832da5-26da-4193-bb58-78a2b89c9790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T15:52:56.431995Z",
     "iopub.status.busy": "2024-01-17T15:52:56.431739Z",
     "iopub.status.idle": "2024-01-17T15:52:56.437327Z",
     "shell.execute_reply": "2024-01-17T15:52:56.436792Z",
     "shell.execute_reply.started": "2024-01-17T15:52:56.431964Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "Act as a Growth assistant who has access to a list of interactions from content that enable the user to get marketing qualified contacts.\n",
    "Your role is to manage and optimize the list of people who interacted on the content, ensuring to extract only the most qualified contacts to feed the sales representative.\n",
    "This week '{TW}' the '{entity_name}' generated {total_leads} leads from them {new_leads} are new thanks to its following posts: {post_data}. \n",
    "Here is the list with the highest interaction score: {\" ,\".join(prompt_data)}.\n",
    "Please remember the user that you don't have access to all the list due to the limit of the context window.\n",
    "The first message should be about presenting yourself and analyze briefly '{entity_name}' new interactions with a maximum of 3 bullet points.\n",
    "Then, you will display the image inside the markdown of the chat about the leads evolution over the weeks: [![Leads Evolution]({image_url})({image_html})].\n",
    "You must ALWAYS show the image in the first message.\n",
    "Be casual, but professional. Wait for the first answer from the user, and then start with the first high-level analysis. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c97c27b-06d4-474c-a347-08a6df8856de",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Create commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c78707b5-9496-44d5-a0b3-26fa4e88004e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T15:52:56.439173Z",
     "iopub.status.busy": "2024-01-17T15:52:56.438933Z",
     "iopub.status.idle": "2024-01-17T15:52:58.904225Z",
     "shell.execute_reply": "2024-01-17T15:52:58.903639Z",
     "shell.execute_reply.started": "2024-01-17T15:52:56.439144Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👌 Well done! Your Notebook has been sent to production.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    if (!window.copyToClipboard) {\n",
       "        window.copyToClipboard = (text) => {\n",
       "            const dummy = document.createElement(\"textarea\");\n",
       "            document.body.appendChild(dummy);\n",
       "            dummy.value = text;\n",
       "            dummy.select();\n",
       "            document.execCommand(\"copy\");\n",
       "            document.body.removeChild(dummy);\n",
       "        }\n",
       "    }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f198a2b6694cafa2ed401cd6e3f3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Copy URL', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a33233fa1f543578a4e060386c064b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS: to remove the \"Notebook as API\" feature, just replace .add by .delete\n",
      "👌 Well done! Your Notebook has been sent to production.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    if (!window.copyToClipboard) {\n",
       "        window.copyToClipboard = (text) => {\n",
       "            const dummy = document.createElement(\"textarea\");\n",
       "            document.body.appendChild(dummy);\n",
       "            dummy.value = text;\n",
       "            dummy.select();\n",
       "            document.execCommand(\"copy\");\n",
       "            document.body.removeChild(dummy);\n",
       "        }\n",
       "    }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61083f7ce47b410580e552205844213d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Copy URL', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8657e2fb5a04348aebf46aac56d4862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS: to remove the \"Notebook as API\" feature, just replace .add by .delete\n",
      "👌 Well done! Your Notebook has been sent to production.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    if (!window.copyToClipboard) {\n",
       "        window.copyToClipboard = (text) => {\n",
       "            const dummy = document.createElement(\"textarea\");\n",
       "            document.body.appendChild(dummy);\n",
       "            dummy.value = text;\n",
       "            dummy.select();\n",
       "            document.execCommand(\"copy\");\n",
       "            document.body.removeChild(dummy);\n",
       "        }\n",
       "    }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca91a0deb6940a69e36b718a61a7139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Copy URL', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7a9859a8ee43fc842bf285de102e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS: to remove the \"Notebook as API\" feature, just replace .add by .delete\n",
      "[\n",
      "    {\n",
      "        \"name\": \"HubSpot_Connect\",\n",
      "        \"avatar\": \"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/HubSpot.png\",\n",
      "        \"action\": {\n",
      "            \"request_type\": \"POST\",\n",
      "            \"url\": \"https://public.naas.ai/ZmxvcmVudC00MG5hYXMtMkVhaQ==/notebook/4c9eece13a41e6df74605815e8269de0c1f76c2391c2ea7650d10e685d4c\",\n",
      "            \"payload\": {\n",
      "                \"hs_access_token\": {\n",
      "                    \"type\": \"str\",\n",
      "                    \"description\": \"This variable stores an access token used for accessing the HubSpot API. This value will be stored under the secret 'HS_ACCESS_TOKEN'.\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"description\": \"This command integrates your HubSpot access token into the Naas Lab secret manager.\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"LinkedIn_Connect\",\n",
      "        \"avatar\": \"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/LinkedIn.png\",\n",
      "        \"action\": {\n",
      "            \"request_type\": \"POST\",\n",
      "            \"url\": \"https://public.naas.ai/ZmxvcmVudC00MG5hYXMtMkVhaQ==/notebook/ce7ad3841a87dd74fb8086f05748492b66edec043dc38ff8ac4c21ba2ba5\",\n",
      "            \"payload\": {\n",
      "                \"li_at\": {\n",
      "                    \"type\": \"str\",\n",
      "                    \"description\": \"Cookie used to authenticate Members and API clients. This value will be stored under the secret 'LINKEDIN_LI_AT'.\",\n",
      "                    \"default\": \"None\"\n",
      "                },\n",
      "                \"JSESSIONID\": {\n",
      "                    \"type\": \"str\",\n",
      "                    \"description\": \"Cookie used for Cross Site Request Forgery (CSRF) protection and URL signature validation. This value will be stored under the secret 'LINKEDIN_JSESSIONID'.\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"description\": \"This command integrates your LinkedIn cookies into the Naas Lab secret manager.\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"OpenAI_Connect\",\n",
      "        \"avatar\": \"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/OpenAI.png\",\n",
      "        \"action\": {\n",
      "            \"request_type\": \"POST\",\n",
      "            \"url\": \"https://public.naas.ai/ZmxvcmVudC00MG5hYXMtMkVhaQ==/notebook/74e763d8b20069800562d679dd9021116a84aab1ed714cdb58793c1319b8\",\n",
      "            \"payload\": {\n",
      "                \"api_key\": {\n",
      "                    \"type\": \"str\",\n",
      "                    \"description\": \"OpenAI API key. This value will be stored under the secret 'OPENAI_API_KEY'.\",\n",
      "                    \"default\": \"None\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"description\": \"This command integrates your OpenAI api key into the Naas Lab secret manager.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "commands = create_command(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce4521-731f-42cb-8ace-0e7611c750b3",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d959298-e04a-459f-85d9-1b12bb5754c9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Create Naas Chat plugin\n",
    "This function will generate the plugin in JSON format and also verify if your prompt adheres to the recommended limit, which is set at 20% of the maximum tokens allowed by the model. Then, it will save your plugin in your local environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac0af791-9f6d-4da8-82d0-1defed0bc59f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T15:52:58.907117Z",
     "iopub.status.busy": "2024-01-17T15:52:58.906708Z",
     "iopub.status.idle": "2024-01-17T15:52:59.139347Z",
     "shell.execute_reply": "2024-01-17T15:52:59.138683Z",
     "shell.execute_reply.started": "2024-01-17T15:52:58.907085Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Be careful, your system prompt looks too big. Tokens: 57971 (limit recommended: 20% -> 25600)\n",
      "💾 Plugin successfully saved. You can use it in your Naas Chat with: /home/ftp/abi/outputs/jeremy_ravenel/plugins/🚀_growth_assistant.json\n"
     ]
    }
   ],
   "source": [
    "# Create plugin\n",
    "plugin_file_path = naas_chat_plugin.create_plugin(\n",
    "    name=name,\n",
    "    prompt=system_prompt,\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    output_path=output_path,\n",
    "    description=description,\n",
    "    avatar=avatar,\n",
    "    commands=commands\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b625a0-f39b-4c7e-82f5-cc58a11ec902",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Create asset\n",
    "This asset can be utilized by using the command `/use` in your Naas Chat or by simply clicking on the link provided in the last cell output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39437f23-bcf8-40df-9538-32b3cac1c8fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T15:52:59.144203Z",
     "iopub.status.busy": "2024-01-17T15:52:59.142541Z",
     "iopub.status.idle": "2024-01-17T15:52:59.902974Z",
     "shell.execute_reply": "2024-01-17T15:52:59.901673Z",
     "shell.execute_reply.started": "2024-01-17T15:52:59.144167Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👌 Well done! Your Assets has been sent to production.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    if (!window.copyToClipboard) {\n",
       "        window.copyToClipboard = (text) => {\n",
       "            const dummy = document.createElement(\"textarea\");\n",
       "            document.body.appendChild(dummy);\n",
       "            dummy.value = text;\n",
       "            dummy.select();\n",
       "            document.execCommand(\"copy\");\n",
       "            document.body.removeChild(dummy);\n",
       "        }\n",
       "    }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a825d4d1bb40598972ef2adfe90c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Copy URL', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251d495c0bce4db9a04d1511b2b98378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PS: to remove the \"Assets\" feature, just replace .add by .delete\n",
      "https://public.naas.ai/ZmxvcmVudC00MG5hYXMtMkVhaQ==/asset/4b5b95586486b6a9c588380bdf549361f17f596b3df29c3569a8e115035a\n"
     ]
    }
   ],
   "source": [
    "plugin_url = naas.asset.add(plugin_file_path, params={\"inline\": True})\n",
    "print(plugin_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde0d3d-de48-4307-bd6a-63081b1e436c",
   "metadata": {},
   "source": [
    "### Create new chat\n",
    "NB: You don't need to click on 'Create New Chat' everytime you update your system prompt, you can use the command `/refresh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "221fab1a-663b-4aa7-871d-f8ff7b1e2a18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T15:52:59.904168Z",
     "iopub.status.busy": "2024-01-17T15:52:59.903912Z",
     "iopub.status.idle": "2024-01-17T15:52:59.912404Z",
     "shell.execute_reply": "2024-01-17T15:52:59.911852Z",
     "shell.execute_reply.started": "2024-01-17T15:52:59.904145Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[Create New Chat](https://naas.ai/chat/use?plugin_url=https://public.naas.ai/ZmxvcmVudC00MG5hYXMtMkVhaQ==/asset/4b5b95586486b6a9c588380bdf549361f17f596b3df29c3569a8e115035a)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(f\"[Create New Chat](https://naas.ai/chat/use?plugin_url={plugin_url})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2f65a-c24b-4d33-b24d-7ce2dacb834e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "d376a4cfdf00d1197e0cd54cf4e801052d22a6e15133079bf4d3ff56c29fc5a0",
   "notebook_path": "GitHub/GitHub_Create_plugin_with_commands.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
