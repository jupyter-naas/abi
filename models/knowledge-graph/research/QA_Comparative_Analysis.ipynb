{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"Content\" src=\"https://naasai-public.s3.eu-west-3.amazonaws.com/abi-demo/content_creation.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# QA - Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #neo4j #abi #knowledgegraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Florent Ravenel](https://www.linkedin.com/in/florent-ravenel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Last update:** 2024-04-08 (Created: 2024-03-25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Description:** This notebook perform a QA comparative analysis between system prompt, vector search and knowledge graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import naas\n",
    "import pandas as pd\n",
    "from naas_drivers import gsheet\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "try:\n",
    "    from langchain.graphs import Neo4jGraph\n",
    "    from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "    from langchain.chains import RetrievalQA, GraphCypherQAChain\n",
    "    from langchain.agents import initialize_agent, Tool\n",
    "    from langchain.agents import AgentType\n",
    "except:\n",
    "    !pip install langchain==0.1.13 --user\n",
    "    from langchain.graphs import Neo4jGraph\n",
    "    from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "    from langchain.chains import RetrievalQA, GraphCypherQAChain\n",
    "    from langchain.agents import initialize_agent, Tool\n",
    "    from langchain.agents import AgentType\n",
    "try:\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from langchain_openai import ChatOpenAI\n",
    "except:\n",
    "    !pip install langchain-openai==0.1.1 --user\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from langchain_openai import ChatOpenAI\n",
    "import naas_data_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "entity_index = \"0\"\n",
    "spreadsheet_url = pload(os.path.join(naas_data_product.OUTPUTS_PATH, \"entities\", entity_index), \"abi_spreadsheet\") or \"\"\n",
    "sheet_posts = \"DATASET_POSTS\"\n",
    "sheet_qa = \"QA\"\n",
    "api_key = os.environ.get(\"NAAS_API_TOKEN\") or naas.secret.get('NAAS_API_TOKEN')\n",
    "os.environ['OPENAI_API_KEY'] = naas.secret.get(\"OPENAI_API_KEY\") or \"\"\n",
    "url = naas.secret.get(\"NEO4J_URI\")\n",
    "username = naas.secret.get(\"NEO4J_USERNAME\")\n",
    "password = naas.secret.get(\"NEO4J_PASSWORD\")\n",
    "plugin_path = os.path.join(\"..\", \"outputs\", \"content_assistant.json\")\n",
    "model_id = \"c6f0d70f-faa4-492f-81b7-4b6aba79e227\"\n",
    "\n",
    "# Outputs\n",
    "sheet_result = \"QA_RESULT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get plugin slug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the JSON file\n",
    "with open(plugin_path) as json_file:\n",
    "    plugin = json.load(json_file)\n",
    "    \n",
    "plugin_slug = plugin.get(\"slug\")\n",
    "plugin_url = plugin.get(\"url\")\n",
    "print(\"Plugin slug:\", plugin_slug)\n",
    "print(\"Plugin URL:\", plugin_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get plugin ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_plugin_id(api_key, plugin_url):\n",
    "    workspaces = list_workspaces(api_key)\n",
    "    for workspace in workspaces.get(\"workspaces\"):\n",
    "        workspace_id = workspace.get(\"id\")\n",
    "        is_personal = workspace.get(\"is_personal\")\n",
    "        if is_personal:\n",
    "            break\n",
    "    print(\"Personal workspace ID:\", workspace_id)\n",
    "    \n",
    "    workspace_plugins = list_workspace_plugins(api_key, workspace_id)\n",
    "    for workspace_plugin in workspace_plugins.get(\"workspace_plugins\"):\n",
    "        plugin_id = workspace_plugin.get(\"id\")\n",
    "        plugin = json.loads(workspace_plugin.get(\"payload\"))\n",
    "        url = plugin.get(\"url\")\n",
    "        if url == plugin_url:\n",
    "            break\n",
    "    print(\"Plugin ID:\", plugin_id)\n",
    "    return plugin_id\n",
    "\n",
    "plugin_id = get_plugin_id(api_key, plugin_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_qa = gsheet.connect(spreadsheet_url).get(sheet_name=sheet_qa)\n",
    "if not isinstance(df_qa, pd.DataFrame):\n",
    "    df_qa = pd.DataFrame()\n",
    "print(\"- QA:\", len(df_qa))\n",
    "question_test = df_qa.loc[0, \"QUESTION\"]\n",
    "print(\"-> Question (test):\", question_test)\n",
    "df_qa.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Create Chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_chat_completion(\n",
    "    api_key,\n",
    "    chat_id,\n",
    "    model_id,\n",
    "    message,\n",
    "    temperature,\n",
    "    plugin_id\n",
    "):\n",
    "    url = f\"https://api.naas.ai/chat/{chat_id}/completion\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    data = json.dumps(\n",
    "        {\n",
    "            \"id\": chat_id,\n",
    "            \"model_id\": model_id,\n",
    "            \"plugin_id\": plugin_id,\n",
    "            \"payload\": json.dumps(\n",
    "                {\n",
    "                    \"prompt\": message,\n",
    "                    \"temperature\": temperature,\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    response = requests.post(url, headers=headers, data=data)\n",
    "    return response.json()\n",
    "\n",
    "def create_chat(\n",
    "    api_key,\n",
    "    chat_name,\n",
    "):\n",
    "    url = \"https://api.naas.ai/chat\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"name\": chat_name,\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "chat_name = \"Test Content Assistant\"\n",
    "result = create_chat(api_key, chat_name)\n",
    "chat_id = result.get(\"chat\").get(\"id\")\n",
    "\n",
    "# Test system prompt\n",
    "prompt_result = \"\"\n",
    "try:\n",
    "    model_id = \"c6f0d70f-faa4-492f-81b7-4b6aba79e227\"\n",
    "    message = f\"@content-assistant/{plugin_slug} {question_test}\"\n",
    "    temperature = 0.5\n",
    "    result = create_chat_completion(api_key, chat_id, model_id, message, temperature, plugin_id)\n",
    "    if len(result.get(\"completion\")) > 0:\n",
    "        prompt_result = result.get(\"completion\").get(\"messages\")[1].get(\"message\")\n",
    "except Exception as e:\n",
    "    prompt_result = e\n",
    "print(\"Prompt result:\", prompt_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T17:08:46.855856Z",
     "iopub.status.busy": "2024-03-25T17:08:46.855622Z",
     "iopub.status.idle": "2024-03-25T17:08:46.860216Z",
     "shell.execute_reply": "2024-03-25T17:08:46.859554Z",
     "shell.execute_reply.started": "2024-03-25T17:08:46.855832Z"
    },
    "tags": []
   },
   "source": [
    "### Create Vector Index & Retrieval QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_posts = gsheet.connect(spreadsheet_url).get(sheet_name=sheet_posts)\n",
    "df_posts.head(1)\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(),\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    index_name='content',\n",
    "    node_label=\"Content\",\n",
    "    text_node_properties=list(df_posts.columns.str.lower()),\n",
    "    embedding_node_property='embedding',\n",
    ")\n",
    "\n",
    "vector_qa = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_index.as_retriever()\n",
    ")\n",
    "\n",
    "# Test vector search result\n",
    "vector_result = \"\"\n",
    "try:\n",
    "    vector_qa_result = vector_qa.invoke(question_test)\n",
    "    if len(vector_qa_result) > 0:\n",
    "        vector_result = vector_qa_result.get(\"result\")\n",
    "except Exception as e:\n",
    "    vector_result = e\n",
    "print(\"Vector Result:\", vector_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphCypherQAChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=url, \n",
    "    username=username, \n",
    "    password=password\n",
    ")\n",
    "\n",
    "graph.refresh_schema()\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    cypher_llm = ChatOpenAI(temperature=0, model_name='gpt-4'),\n",
    "    qa_llm = ChatOpenAI(temperature=0), graph=graph, verbose=True,\n",
    ")\n",
    "\n",
    "# Test KG result\n",
    "kg_result = \"\"\n",
    "try:\n",
    "    cypher_chain_result = cypher_chain.invoke(question_test)\n",
    "    if len(cypher_chain_result) > 0:\n",
    "        kg_result = cypher_chain_result.get(\"result\")\n",
    "except Exception as e:\n",
    "    kg_result = e\n",
    "print(\"KG Result:\", kg_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_output = df_qa.copy()\n",
    "\n",
    "for index, row in df_output.iterrows():\n",
    "    question = row[\"QUESTION\"]\n",
    "    print(\"Question:\", question)\n",
    "    \n",
    "    # Test system prompt\n",
    "    prompt_result = \"\"\n",
    "    try:\n",
    "        message = f\"{plugin_slug} {question}\"\n",
    "        temperature = 0.5\n",
    "        result = create_chat_completion(api_key, chat_id, model_id, message, temperature, plugin_id)\n",
    "        if len(result.get(\"completion\")) > 0:\n",
    "            prompt_result = result.get(\"completion\").get(\"messages\")[1].get(\"message\")\n",
    "        time.sleep(3)\n",
    "    except Exception as e:\n",
    "        prompt_result = e\n",
    "    print(\"Prompt Result:\", prompt_result)\n",
    "    print()\n",
    "    \n",
    "    # Test vector search result\n",
    "    vector_result = \"\"\n",
    "    try:\n",
    "        vector_qa_result = vector_qa.invoke(question)\n",
    "        if len(vector_qa_result) > 0:\n",
    "            vector_result = vector_qa_result.get(\"result\")\n",
    "    except Exception as e:\n",
    "        vector_result = e\n",
    "    print(\"Vector Result:\", vector_result)\n",
    "    print()\n",
    "    \n",
    "    # Test KG result\n",
    "    kg_result = \"\"\n",
    "    try:\n",
    "        cypher_chain_result = cypher_chain.invoke(question)\n",
    "        if len(cypher_chain_result) > 0:\n",
    "            kg_result = cypher_chain_result.get(\"result\")\n",
    "    except Exception as e:\n",
    "        kg_result = e\n",
    "    print(\"KG Result:\", kg_result)  \n",
    "    print()\n",
    "\n",
    "    df_output.loc[index, \"SYSTEM_PROMPT\"] = prompt_result\n",
    "    df_output.loc[index, \"VECTOR_SEARCH\"] = vector_result\n",
    "    df_output.loc[index, \"KNOWLEDGE_GRAPH\"] = kg_result\n",
    "    print()\n",
    "    \n",
    "df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send data to spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gsheet.connect(spreadsheet_url).send(data=df_output, sheet_name=sheet_result, append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
