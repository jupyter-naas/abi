{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728761a8-838d-44e8-b168-d600e7225020",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"Content\" src=\"https://naasai-public.s3.eu-west-3.amazonaws.com/abi-demo/content_creation.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13166d6d-0609-44fb-b91e-949ad8018f8b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Content - Create POSTS database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3bdfc4-23ba-495e-869e-cd754a5beeac",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #content #posts #database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e0d98-036c-478e-8831-cdb5e7b8a22b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Florent Ravenel](https://www.linkedin.com/in/florent-ravenel/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497de15-2a8d-4609-8139-35461bc13ee4",
   "metadata": {
    "papermill": {},
    "tags": [
     "description"
    ]
   },
   "source": [
    "**Description:** This notebook generates OBG POSTS using the data extracted by the configured connections. Currently, it only supports LinkedIn posts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "input_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9e878-2148-47e3-a13d-09ba77202893",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fad521a-4a18-4dc7-b13d-98a37172715b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from naas_drivers import gsheet\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date\n",
    "import naas_data_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec39e794-a8cd-41b8-9489-9ddb962a601c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup variables\n",
    "**Inputs**\n",
    "- `entity_dir`: This variable represents the entity directory.\n",
    "- `entity_name`: This variable holds the entity name.\n",
    "- `input_dir`: Input directory to retrieve file from.\n",
    "- `file_name`: Name of the file to be retrieved.\n",
    "\n",
    "**Outputs**\n",
    "- `spreadsheet_url`: Google Sheets spreadsheet URL.\n",
    "- `sheet_name`: Google Sheets sheet name.\n",
    "- `output_dir`: Output directory\n",
    "- `file_content`: Name of the file to be saved in your local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34bff6-9136-4aaf-a692-b38129b7de83",
   "metadata": {
    "papermill": {},
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "entity_index = \"0\"\n",
    "entity_dir = pload(os.path.join(naas_data_product.OUTPUTS_PATH, \"entities\", entity_index), \"entity_dir\") or \"\"\n",
    "entity_name = pload(os.path.join(naas_data_product.OUTPUTS_PATH, \"entities\", entity_index), \"entity_name\") or \"\"\n",
    "input_dir = os.path.join(entity_dir, \"content-engine\", date.today().isoformat())\n",
    "file_name = \"linkedin_posts\"\n",
    "\n",
    "# Outputs\n",
    "spreadsheet_url = pload(os.path.join(naas_data_product.OUTPUTS_PATH, \"entities\", entity_index), \"abi_spreadsheet\") or \"\"\n",
    "sheet_name = \"POSTS\"\n",
    "output_dir = os.path.join(entity_dir, \"content-engine\", date.today().isoformat())\n",
    "file_content = \"posts\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82dbc1b-acf3-4e44-8dac-e4f631787afa",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34407369-03a1-45c4-9768-03222224612b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_init = gsheet.connect(spreadsheet_url).get(sheet_name=sheet_name)\n",
    "if not isinstance(df_init, pd.DataFrame):\n",
    "    df_init = pd.DataFrame()\n",
    "print(\"- Posts db (init):\", len(df_init))\n",
    "df_init.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568d91f-f088-4461-8911-95d8ad591229",
   "metadata": {},
   "source": [
    "### Get posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57461362-178a-4dbd-81d1-dd27a6291c47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_posts = pload(input_dir, file_name)    \n",
    "print(\"- New posts published:\", len(df_posts))\n",
    "df_posts.head(len(df_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1683da4f-41e3-4e11-9c3a-bf01af8ebefe",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823374f-9255-4e54-a125-c8be746acdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_db(\n",
    "    df_new,\n",
    "    df_init,\n",
    "    entity_name\n",
    "):\n",
    "    # Init\n",
    "    df = df_new.copy()\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        # Format published date\n",
    "        df[\"PUBLISHED_DATE\"] = pd.to_datetime(df['PUBLISHED_DATE'].str[:19], format='%Y-%m-%d %H:%M:%S').dt.tz_localize(pytz.timezone(\"Europe/Paris\")).dt.tz_convert(TIMEZONE).dt.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "        df[\"DATE_EXTRACT\"] = pd.to_datetime(df['DATE_EXTRACT'].str[:19], format='%Y-%m-%d %H:%M:%S').dt.tz_localize(pytz.timezone(\"Europe/Paris\")).dt.tz_convert(TIMEZONE).dt.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "        # Cleaning: if title is None and Content = 'Video (native)' -> \"Live\"\n",
    "        df.loc[(df[\"TITLE\"].astype(str) == 'None') & (df[\"CONTENT\"] == 'Video (native)'), \"TITLE\"] = \"Live\"\n",
    "        df.loc[df[\"TITLE\"].astype(str) == 'Live', \"TEXT\"] = \"Live\"\n",
    "        df.loc[(df[\"CONTENT\"] == 'Article') & (df[\"TEXT\"].astype(str) == 'None'), \"TEXT\"] = \"Article: \" + df[\"CONTENT_URL\"]\n",
    "        df.loc[(df[\"CONTENT\"] == 'Article') & (df[\"TITLE\"].astype(str) == 'None'), \"TITLE\"] = \"Article: \" + df[\"CONTENT_URL\"]\n",
    "        df.loc[(df[\"CONTENT\"] == 'Article') & (df[\"TEXT\"].astype(str) != 'None'), \"TEXT\"] = df[\"TEXT\"].astype(str) + \"\\nArticle: \" + df[\"CONTENT_URL\"]\n",
    "\n",
    "        # Cleaning: rename columns + None to NA\n",
    "        to_rename = {\n",
    "            \"POST_URL\": \"CONTENT_URL\",\n",
    "            \"TEXT\": \"CONTENT\",\n",
    "            \"CHARACTER_COUNT\": \"CONTENT_LENGTH\",\n",
    "            \"TAGS\": \"KEYWORDS\",\n",
    "        }\n",
    "        df = df.drop([\"CONTENT_URL\", \"CONTENT\"], axis=1).rename(columns=to_rename)\n",
    "        df.KEYWORDS = df.KEYWORDS.astype(str).str.replace(\"None\", \"NA\")\n",
    "        df.insert(loc=0, column=\"ENTITY\", value=entity_name)\n",
    "\n",
    "        # Select\n",
    "        to_select = [\n",
    "            \"ENTITY\",\n",
    "            \"PUBLISHED_DATE\",\n",
    "            \"TITLE\",\n",
    "            \"CONTENT\",\n",
    "            \"CONTENT_LENGTH\",\n",
    "            \"KEYWORDS\",\n",
    "            \"VIEWS\",\n",
    "            \"LIKES\",\n",
    "            \"COMMENTS\",\n",
    "            \"SHARES\",\n",
    "            \"ENGAGEMENT_SCORE\",\n",
    "            \"CONTENT_URL\",\n",
    "            \"DATE_EXTRACT\"\n",
    "        ]\n",
    "        df = df[to_select]\n",
    "\n",
    "        # Add new data\n",
    "        df.insert(loc=1, column=\"SCENARIO\", value=pd.to_datetime(df['PUBLISHED_DATE'].str[:19], format='%Y-%m-%d %H:%M:%S').dt.strftime(\"W%W-%Y\"))\n",
    "        df.insert(loc=2, column=\"SOURCE\", value=\"LinkedIn\")\n",
    "        df.insert(loc=4, column=\"DATE\", value=pd.to_datetime(df['PUBLISHED_DATE'].str[:19], format='%Y-%m-%d %H:%M:%S').dt.strftime(\"%a. %d %b.\"))\n",
    "        df.insert(loc=5, column=\"TIME\", value=pd.to_datetime(df['PUBLISHED_DATE'].str[:19], format='%Y-%m-%d %H:%M:%S').dt.strftime('%HH%M'))\n",
    "\n",
    "        # Manage empty title\n",
    "        df.loc[df.TITLE == \"\", \"TITLE\"] = df[\"CONTENT\"]\n",
    "        df[\"TITLE\"] = df.apply(lambda row: row[\"TITLE\"].split(\"\\n\")[1] if row[\"TITLE\"].startswith(\"\\n\") else row[\"TITLE\"], axis=1)\n",
    "        df.loc[df.TITLE.str[:2] == \"\\n\", \"TITLE\"] = df[\"CONTENT\"]\n",
    "    \n",
    "    # Concat with init\n",
    "    df = pd.concat([df, df_init], axis=0)\n",
    "    if len(df) > 0:\n",
    "        # Drop duplicates\n",
    "        df = df.drop_duplicates(\"CONTENT_URL\", keep='first')\n",
    "\n",
    "        # Sort values\n",
    "        df[\"SCENARIO_ORDER\"] = pd.to_datetime(df['PUBLISHED_DATE'].str[:19], format='%Y-%m-%d %H:%M:%S').dt.strftime(\"%Y%W\")\n",
    "        df = df.sort_values(by=[\"SCENARIO_ORDER\", \"ENTITY\", \"PUBLISHED_DATE\"], ascending=[False, True, False])\n",
    "    return df.reset_index(drop=True)\n",
    "    \n",
    "df_content = create_db(df_posts, df_init, entity_name)\n",
    "print(\"- Post db:\", len(df_content))\n",
    "df_content.head(len(df_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "output_cell",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03167fbc-99a5-45a4-b186-522f54ce7db6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf636b-20c1-4e2e-b6dd-23ac07fbfa46",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdump(output_dir, df_content, file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b11537-6391-4022-b55d-dd1f84cbe97f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Send \"Content\" to Google Sheets spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e91b35-c1f8-4fe6-ae78-a2d4b79c8be7",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "send_data_to_gsheet(df_content, df_init, spreadsheet_url, sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc4241-9a56-4495-9369-bf3de2bcfb42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "cf32ecf61a1d6fdcae3273e7e70026564087776ace44ace0a939c08a2085586f",
   "notebook_path": "Google Sheets/Google_Sheets_Send_data.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
