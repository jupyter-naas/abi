{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d8ed01-87f0-40d8-9ea7-af2db69be6f5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"YouTube.png\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/YouTube.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99a80ea-28de-4f27-912c-49c90908e001",
   "metadata": {},
   "source": [
    "# YouTube - Extract Clip and Generate Content Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d739464-ce89-420f-9e5a-2045e8ef4a24",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #content #youtube #generativeai #genai #chat #ai #automation #prompt #command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa448c3f-073b-428d-acb8-ba8058b55d8f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Jeremy Ravenel](https://www.linkedin.com/in/jeremyravenel/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef196d-a35a-4ed7-b610-fe6968afae08",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Last update:** 2023-10-10 (Created: 2023-09-22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf71dde-bf59-4654-80d8-f73e1fa5b59a",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Description:**\n",
    "This notebook template is a powerful tool for content creators and marketers who want to leverage YouTube videos to extract valuable insights and generate content ideas. With this template, you can easily extract clips from YouTube videos, capture key moments, and brainstorm creative content ideas based on the extracted clips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26dd498-0b58-4f86-9036-4f00292ee400",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Key Features:**\n",
    "\n",
    "1ï¸âƒ£ YouTube Video Extraction: Seamlessly extract YouTube videos using the YouTube Data API, allowing you to access a vast library of content for analysis and inspiration.\n",
    "\n",
    "2ï¸âƒ£ Clip Extraction: Effortlessly extract specific clips from the YouTube videos, enabling you to focus on the most relevant and engaging moments that resonate with your target audience.\n",
    "\n",
    "3ï¸âƒ£ Content Ideas Generation: Leverage the extracted clips to spark your creativity and generate a wide range of content ideas. Whether you're creating blog posts, social media content, or video scripts, this template will help you brainstorm innovative and captivating ideas.\n",
    "\n",
    "4ï¸âƒ£ Timestamp Integration: Automatically integrate timestamps into the extracted clips, making it easy to reference and navigate to specific moments within the original YouTube videos.\n",
    "\n",
    "5ï¸âƒ£ Collaboration and Sharing: Collaborate with your team by sharing the notebook template, allowing everyone to contribute their ideas and insights. Foster a creative environment where the power of collective thinking fuels your content creation process.\n",
    "\n",
    "6ï¸âƒ£ Documentation and Export: Document your content ideas, insights, and analysis within the notebook template. Export your findings to various formats, including PDF, Markdown, or HTML, for easy sharing and reference.\n",
    "\n",
    "Whether you're a content creator, marketer, or strategist, this notebook template empowers you to extract, analyze, and generate captivating content ideas from YouTube videos. Unleash your creativity, tap into the vast YouTube library, and create content that resonates with your audience like never before. ðŸš€ðŸ’¡ #YouTubeContentIdeas #ContentCreation #VideoMarketing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbdada1-0f96-423e-aac2-95e8071e3c98",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4fab27-fe02-4bfc-8268-dd91d5dd90af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-24T12:46:17.614183Z",
     "iopub.status.busy": "2023-08-24T12:46:17.613891Z",
     "iopub.status.idle": "2023-08-24T12:46:17.619911Z",
     "shell.execute_reply": "2023-08-24T12:46:17.619321Z",
     "shell.execute_reply.started": "2023-08-24T12:46:17.614153Z"
    }
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a54be13-a8a2-46a1-816f-4027b1573c40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import naas\n",
    "try:\n",
    "    from pytube import YouTube\n",
    "except:\n",
    "    !pip install pytube --user\n",
    "    from pytube import YouTube\n",
    "try:\n",
    "    import moviepy\n",
    "except:\n",
    "    !pip install moviepy --user\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from moviepy.editor import AudioFileClip, VideoFileClip\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except:\n",
    "    !pip install tqdm --user\n",
    "    from tqdm import tqdm\n",
    "import openai\n",
    "import concurrent.futures\n",
    "import math\n",
    "import os\n",
    "import naas_data_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01edf413-1b80-47c6-9ffe-3d33f043cc04",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afe20a-fb8d-4094-9c4d-ea9af02ac7ec",
   "metadata": {
    "papermill": {},
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Mandatory\n",
    "youtube_url = \"https://www.youtube.com/watch?v=-DVyjdw4t9I\"\n",
    "start_time = \"00:00:00\"\n",
    "end_time = \"00:06:00\"\n",
    "name = \"Guido van Rossum: Code Readbilty, Indentations and Bugs\"\n",
    "\n",
    "# Optional\n",
    "openai.api_key = naas.secret.get(\"OPENAI_API_KEY\")\n",
    "text_model = \"gpt-4\"\n",
    "audio_model = \"whisper-1\"\n",
    "output_dir = os.path.join(naas_data_product.ROOT_PATH, \"outputs\", \"content-engine\", \"YouTube_Extract_Clip_and_Generate_Content_Ideas\")\n",
    "os.makedirs(output_dir, exist_ok=True) # Create dirs\n",
    "video_file_path = os.path.join(output_dir,  f\"{name}.3gpp\")\n",
    "clip_file_path = os.path.join(output_dir,  f\"{name}.mp4\")\n",
    "audio_file_path = clip_file_path.replace('.mp4', '.mp3')\n",
    "content_file_path = os.path.join(output_dir,  f\"Content_{name}.md\")\n",
    "\n",
    "# Webhook body\n",
    "body = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4d146-dc26-4622-90c5-03b37eb4efc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T17:20:36.759189Z",
     "iopub.status.busy": "2023-09-26T17:20:36.758881Z",
     "iopub.status.idle": "2023-09-26T17:20:36.765546Z",
     "shell.execute_reply": "2023-09-26T17:20:36.764836Z",
     "shell.execute_reply.started": "2023-09-26T17:20:36.759155Z"
    },
    "papermill": {},
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "### Setup parameters\n",
    "The webhook body will be injected below this cell when the webhook is triggered. \n",
    "Therefore, it is important to set up how you will handle the injected variable from the body in order to make your script work.\n",
    "To receive the body from the webhook, please ensure that this cell is tagged as \"parameters\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c8cf9-d71e-4e6a-9048-d78376961a0c",
   "metadata": {
    "papermill": {},
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "if len(body) > 0:\n",
    "    youtube_url = body.get(\"youtube_url\")\n",
    "    start_time = body.get(\"start_time\")\n",
    "    end_time = body.get(\"end_time\")\n",
    "    name = body.get(\"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c297a29-f200-47ae-b0b9-b36e7230b795",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T15:15:03.099071Z",
     "iopub.status.busy": "2023-09-06T15:15:03.098839Z",
     "iopub.status.idle": "2023-09-06T15:15:03.102277Z",
     "shell.execute_reply": "2023-09-06T15:15:03.101708Z",
     "shell.execute_reply.started": "2023-09-06T15:15:03.099043Z"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322cd4ec-bf84-4748-9229-734684118fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T18:57:01.509448Z",
     "iopub.status.busy": "2023-10-04T18:57:01.507874Z",
     "iopub.status.idle": "2023-10-04T18:57:01.513081Z",
     "shell.execute_reply": "2023-10-04T18:57:01.511968Z",
     "shell.execute_reply.started": "2023-10-04T18:57:01.508159Z"
    }
   },
   "source": [
    "### Extract Video Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70fcc20-3c06-4860-b403-a7a5246758af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_seconds(end):\n",
    "    h, m, s = map(int, end.split(':'))\n",
    "    return h * 3600 + m * 60 + s\n",
    "\n",
    "def extract_video_clip(\n",
    "    youtube_url,\n",
    "    video_file_path,\n",
    "    clip_file_path,\n",
    "    start_time,\n",
    "    end_time,\n",
    "):\n",
    "    # Download the video\n",
    "    yt = YouTube(f\"{youtube_url}\")\n",
    "\n",
    "    # Check if there are any streams available\n",
    "    if yt.streams:\n",
    "        stream = yt.streams.first()\n",
    "\n",
    "        video_filename = stream.download(output_path=video_file_path)\n",
    "\n",
    "        # Start and end times in seconds\n",
    "        start_time = convert_to_seconds(start_time)\n",
    "        end_time = convert_to_seconds(end_time)\n",
    "\n",
    "        # Cut the video\n",
    "        ffmpeg_extract_subclip(video_filename, start_time, end_time, targetname=clip_file_path)\n",
    "    else:\n",
    "        print(\"No streams available for this video.\")\n",
    "        \n",
    "extract_video_clip(\n",
    "    youtube_url,\n",
    "    video_file_path,\n",
    "    clip_file_path,\n",
    "    start_time,\n",
    "    end_time\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feda49da-e1fe-4c2e-9760-7cc00926610a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-25T15:40:28.701506Z",
     "iopub.status.busy": "2023-09-25T15:40:28.701197Z",
     "iopub.status.idle": "2023-09-25T15:40:28.704869Z",
     "shell.execute_reply": "2023-09-25T15:40:28.704206Z",
     "shell.execute_reply.started": "2023-09-25T15:40:28.701435Z"
    }
   },
   "source": [
    "### Transforming video into audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e9f07-9bcc-4fd2-bcbc-5916841ce967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_video_to_audio(clip_file_path, audio_file_path):\n",
    "    videoclip = VideoFileClip(clip_file_path)\n",
    "    audioclip = videoclip.audio\n",
    "    audioclip.write_audiofile(audio_file_path)\n",
    "    \n",
    "transform_video_to_audio(\n",
    "    clip_file_path,\n",
    "    audio_file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f40943-283c-48a4-a97e-c93ebf048cae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-10T15:46:26.935852Z",
     "iopub.status.busy": "2023-10-10T15:46:26.935618Z",
     "iopub.status.idle": "2023-10-10T15:46:26.939005Z",
     "shell.execute_reply": "2023-10-10T15:46:26.938361Z",
     "shell.execute_reply.started": "2023-10-10T15:46:26.935826Z"
    }
   },
   "source": [
    "### Split audio files in smaller chunks\n",
    "\n",
    "This is actually needed to not reach limits owhen transribing audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c4d419-f449-43d1-af93-a4e97335a145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_audio_file(\n",
    "    output_dir,\n",
    "    audio_file_path,\n",
    "    chunk_length=300\n",
    "):\n",
    "    # Storing chunks that will be returned.\n",
    "    chunks = [] \n",
    "    \n",
    "    # Load audio clip file.\n",
    "    audioclip = AudioFileClip(audio_file_path)\n",
    "\n",
    "    # Determine the duration of the audio file in seconds\n",
    "    duration = audioclip.duration\n",
    "\n",
    "    # Calculate the number of chunks\n",
    "    num_chunks = int(math.ceil(duration / chunk_length))\n",
    "\n",
    "    # Split the audio file and write each chunk to a new file\n",
    "    for i in range(num_chunks):\n",
    "        start_time = i * chunk_length\n",
    "        end_time = (i + 1) * chunk_length\n",
    "        \n",
    "        # Make sure that if the end_time is superior to duration we set it to duration.\n",
    "        # This will happen on the last chunk most of the time.\n",
    "        if end_time > duration:\n",
    "            end_time = duration\n",
    "            \n",
    "        chunk = audioclip.subclip(start_time, end_time)\n",
    "        audio_chunk_path = os.path.join(output_dir, f\"chunk_{i}.mp3\")\n",
    "        \n",
    "        # Write audio chunk\n",
    "        chunk.write_audiofile(audio_chunk_path)\n",
    "        chunks.append(audio_chunk_path)\n",
    "    return chunks\n",
    "\n",
    "audio_file_chunks = chunk_audio_file(output_dir, audio_file_path)\n",
    "audio_file_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3582dbc-c141-4a65-a40e-c7ac157fe79d",
   "metadata": {},
   "source": [
    "### Transcribing audio (.m4a files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b12ce9-22f7-490c-b855-4af5673e183a",
   "metadata": {},
   "source": [
    "The first step in transcribing the audio from a meeting is to pass the audio file of the meeting into openAI /v1/audio API. Whisper, the model that powers the audio API, is capable of converting spoken language into written text. To start, we will avoid passing a prompt or temperature (optional parameters to control the model's output) and stick with the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503d725-c286-4343-b15c-0646fcb14b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _transcribe_audio(audio_file_path):\n",
    "    print(f'âš™ï¸ Transcribing {audio_file_path}')\n",
    "    with open(audio_file_path, 'rb') as audio_file:\n",
    "        transcription = openai.Audio.transcribe(audio_model, audio_file)\n",
    "    \n",
    "    print(f'âœ… Transcribing {audio_file_path} done')\n",
    "    \n",
    "    with open(f'{audio_file_path}.md', 'w') as f:\n",
    "        f.write(transcription['text'])\n",
    "    \n",
    "    return {\n",
    "        'filename': audio_file_path,\n",
    "        'transcript': transcription['text']\n",
    "    }\n",
    "\n",
    "def transcribe_audio(chunks):\n",
    "    # Creating a ThreadPool to have our transcript being done concurently.\n",
    "    # Helpful for long videos.\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=len(chunks)) as executor:\n",
    "        \n",
    "        # Starting execution for each chunk.\n",
    "        futures = [executor.submit(_transcribe_audio, c) for c in chunks]\n",
    "\n",
    "        # Waiting for all transcript to be done.\n",
    "        results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "        \n",
    "        # Sorting results to build the final transcript in the right order.\n",
    "        # Results are grabbed as transcripts are done and are therefore not in ordre by default.\n",
    "        transcript = \" \".join([c['transcript'] for c in sorted(results, key=lambda x: x['filename'])])\n",
    "        return transcript\n",
    "    \n",
    "transcription = transcribe_audio(audio_file_chunks)\n",
    "transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c1ee6-5528-4aea-8715-5ad1924a916b",
   "metadata": {},
   "source": [
    "### Summary extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4cfcab-1ec2-4c32-9c55-46964688365e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_openai_completion(\n",
    "    text_model,\n",
    "    prompt,\n",
    "    transcription,\n",
    "    temperature=0\n",
    "):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=text_model,\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": transcription\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d1368-22f0-4934-8044-0fc39babe9c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_summary = '''\n",
    "You are a highly skilled AI trained in language comprehension and summarization. \n",
    "I would like you to read the following text and summarize it into a concise abstract paragraph. \n",
    "Aim to retain the most important points, providing a coherent and readable summary that could help \n",
    "a person understand the main points of the discussion without needing to read the entire text. \n",
    "Please avoid unnecessary details or tangential points.           \n",
    "'''\n",
    "\n",
    "abstract_summary = create_openai_completion(text_model, prompt_summary, transcription)\n",
    "abstract_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a0137-7da9-4958-aa04-791d9c2e382b",
   "metadata": {},
   "source": [
    "### Key points extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac35c156-6da8-418e-ad9d-3403fa6c58fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_keypoints = '''\n",
    "You are a proficient AI with a specialty in distilling information into key points. \n",
    "Based on the following text, identify and list the main points that were discussed or brought up. \n",
    "These should be the most important ideas, findings, or topics that are crucial to the essence of the discussion. \n",
    "Your goal is to provide a list that someone could read to quickly understand what was talked about.           \n",
    "'''\n",
    "\n",
    "key_points = create_openai_completion(text_model, prompt_keypoints, transcription)\n",
    "key_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee25d5-b355-4f31-8e3e-7dc991491bf5",
   "metadata": {},
   "source": [
    "### Generate Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79696a93-ff37-4de7-bf08-a2fe352399bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_generate_content = '''\n",
    "Now act as an expert LinkedIn & Twitter copywriter with two PhD: one in Natural Language Processing, another in Human Psychology. \n",
    "You are particularly gifted with pattern recognition and writing.\n",
    "You excel in writing viral, yet highly qualitative LinkedIn and Twitter posts. \n",
    "Your content reach averages 500 likes, with >30% of your posts passing the 1000-likes mark. \n",
    "No wonder why you account as some of the most prominent experts in the field.\n",
    "\n",
    "For reference, you know that a good post is:\n",
    "- Engaging\n",
    "- Entertaining\n",
    "- Not too wordy\n",
    "- Concisely written\n",
    "- Factual\n",
    "- Personal\n",
    "- Highly topical.\n",
    "\n",
    "For systematical reference, a good post must be comprising:\n",
    "An irresistible 1-to-3 liner hook that makes it impossible to scroll through\n",
    "An enticing and captivating text that puts the reader into an autopilot kind of mode\n",
    "A spectacular ending either through a well though-out punchline or a compelling call-to-action.\n",
    "Make each sentence catchy. Use bullet points if necessary. \n",
    "Each post has to be be memorable and a standalone value bomb.\n",
    "Use the transcript of the clip I gave you to create 20 posts ideas presented as follow:\n",
    "- Topic: Encouragement and Inspiration\n",
    "- Hook: Aspire to be a programmer who uplifts and inspires others.\n",
    "- Body: Explore the power of encouragement, mentorship, and creating a supportive environment for fellow programmers to thrive.\n",
    "- Asset: An inspiring visual representation emphasizing the importance of encouragement and mentorship in programming.\n",
    "'''\n",
    "\n",
    "generate_content = create_openai_completion(text_model, prompt_generate_content, transcription)\n",
    "generate_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7fb25b-76cc-4133-883c-6f60d1d359cd",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10040c-7c79-4839-8467-f95296ea1e6e",
   "metadata": {},
   "source": [
    "### Summarizing and analyzing the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f491b82e-cf7b-41dc-9fd9-214cebc37745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_report(\n",
    "    abstract_summary,\n",
    "    key_points,\n",
    "    generate_content,\n",
    "):\n",
    "    return {\n",
    "        'abstract_summary': abstract_summary,\n",
    "        'key_points': key_points,\n",
    "        'generate_content': generate_content\n",
    "    }\n",
    "\n",
    "messages = create_report(\n",
    "    abstract_summary,\n",
    "    key_points,\n",
    "    generate_content\n",
    ")\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e988a85d-d404-45e5-8b67-f043e9a8fc92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T15:15:09.022426Z",
     "iopub.status.busy": "2023-09-26T15:15:09.022118Z",
     "iopub.status.idle": "2023-09-26T15:15:09.025782Z",
     "shell.execute_reply": "2023-09-26T15:15:09.025087Z",
     "shell.execute_reply.started": "2023-09-26T15:15:09.022389Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Return JSON response\n",
    "Response sent to the browser before displayed in Chat UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01679911-b144-486a-88de-ed3597e5d895",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# naas.webhook.respond_json(\n",
    "#     {\n",
    "#         \"status\": \"ok\", \n",
    "#         \"message\": message\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90245adc-0ed8-43f6-9845-58cccd446aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
