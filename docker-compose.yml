services:
  abi:
    build:
      context: .
      dockerfile: docker/images/Dockerfile
    ports:
      - 9879:9879
      - 8501:8501
    volumes:
      - ./scripts:/app/scripts
      - ./uv.lock:/app/uv.lock
      - ./config.yaml:/app/config.yaml
      - ./pyproject.toml:/app/pyproject.toml
      - ./Makefile:/app/Makefile
      - ./storage:/app/storage
      - ./src:/app/src
      - ./lib:/app/lib
      - ./README.md:/app/README.md
      - cargo-cache:/root/.cargo
      - venv_cache:/app/.venv
    environment:
      - PYTHONPATH=/app
      - POSTGRES_URL=postgresql://abi_user:abi_password@postgres:5432/abi_memory
    env_file:
      - .env
    command: ["uv", "run"]
    depends_on:
      oxigraph:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - abi-network
    profiles:
      - container  # Only used when explicitly running in container mode
  
  postgres:
    image: postgres:17-alpine
    environment:
      POSTGRES_USER: abi_user
      POSTGRES_PASSWORD: abi_password
      POSTGRES_DB: abi_memory
    ports:
      - 5432:5432
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U abi_user -d abi_memory"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - abi-network
    profiles:
      - local
      - prod
      - container

  oxigraph:
    image: oxigraph/oxigraph:latest
    expose:
      - 7878
    volumes:
      - oxigraph_data:/data
    command: ["serve", "--location", "/data", "--bind", "0.0.0.0:7878"]
    networks:
      - abi-network
    profiles:
      - local
      - prod

  oxigraph-proxy:
    image: nginx:alpine
    ports:
      - 7878:80
    volumes:
      - ./src/core/abi/apps/oxigraph_admin/nginx-oxigraph.conf:/etc/nginx/conf.d/default.conf:ro
      - ./src/core/abi/apps/oxigraph_admin/web:/usr/share/nginx/html/web:ro
    depends_on:
      - oxigraph
    networks:
      - abi-network
    profiles:
      - local
      - prod

  yasgui:
    image: erikap/yasgui:latest
    platform: linux/amd64  # Force x86_64 for compatibility
    ports:
      - 3000:80
    environment:
      - DEFAULT_SPARQL_ENDPOINT=http://127.0.0.1:7878/query
    depends_on:
      - oxigraph
    networks:
      - abi-network
    profiles:
      - local
      - prod

  dagster:
    build:
      context: .
      dockerfile: docker/images/Dockerfile
    ports:
      - 3001:3000  # Changed to 3001 to avoid conflict with yasgui
    volumes:
      - ./scripts:/app/scripts
      - ./uv.lock:/app/uv.lock
      - ./config.yaml:/app/config.yaml
      - ./pyproject.toml:/app/pyproject.toml
      - ./src:/app/src
      - ./lib:/app/lib
      - ./README.md:/app/README.md
      - venv_cache:/app/.venv
      - dagster_home:/app/.dagster
    platform: linux/arm64
    environment:
      - PYTHONPATH=/app
      - DAGSTER_HOME=/app/.dagster
    command: ["sh", "-c", "uv sync --frozen --all-extras && uv run python scripts/generate_dagster_command.py | xargs uv run"]
    networks:
      - abi-network
    profiles:
      - local
      - prod

  # Local AI Models Configuration
  # These services document the local AI model configuration
  # The actual models run via Docker Model Runner on the host
  
  local-chat:
    image: alpine:latest
    command: ["echo", "Local chat model: ai/gemma3:4B-Q4_0 running via Docker Model Runner"]
    environment:
      - MODEL_NAME=ai/gemma3:4B-Q4_0
      - MODEL_TYPE=chat
      - API_ENDPOINT=http://localhost:11434/v1/chat/completions
      - CONTEXT_WINDOW=131072
      - QUANTIZATION=Q4_0
      - PROVIDER=docker-model-runner
    labels:
      - "abi.model.name=ai/gemma3:4B-Q4_0"
      - "abi.model.type=chat"
      - "abi.model.provider=docker-model-runner"
      - "abi.model.endpoint=http://localhost:11434/v1/chat/completions"
      - "abi.model.context_window=131072"
    profiles:
      - local
    restart: "no"

  local-embeddings:
    image: alpine:latest  
    command: ["echo", "Local embedding model: ai/embeddinggemma:300M-Q8_0 (using deterministic embeddings)"]
    environment:
      - MODEL_NAME=ai/embeddinggemma:300M-Q8_0
      - MODEL_TYPE=embeddings
      - DIMENSIONS=768
      - QUANTIZATION=Q8_0
      - PROVIDER=deterministic
      - IMPLEMENTATION=hash-based
    labels:
      - "abi.model.name=ai/embeddinggemma:300M-Q8_0"
      - "abi.model.type=embeddings"
      - "abi.model.provider=deterministic"
      - "abi.model.dimensions=768"
      - "abi.model.implementation=hash-based"
    profiles:
      - local
    restart: "no"

volumes:
  cargo-cache:
  venv_cache:
  oxigraph_data:
  postgres_data:
  dagster_home: 

networks:
  abi-network:
    driver: bridge
