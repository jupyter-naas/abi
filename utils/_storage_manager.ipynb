{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b413d78-e163-4391-ad13-595a19821b1f",
   "metadata": {},
   "source": [
    "# Storage Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a72b38-f6e3-4ffa-9e46-9aaeb2ea7f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pickle\n",
    "from io import BytesIO\n",
    "import os\n",
    "import fnmatch\n",
    "\n",
    "class StorageManager:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        access_key_id,\n",
    "        secret_access_key,\n",
    "        session_token,\n",
    "        bucket_name,\n",
    "        bucket_prefix, \n",
    "    ):\n",
    "        self.access_key_id = access_key_id\n",
    "        self.secret_access_key = secret_access_key\n",
    "        self.session_token = session_token\n",
    "        self.bucket_name = bucket_name\n",
    "        self.bucket_prefix = bucket_prefix\n",
    "        \n",
    "        # Init client\n",
    "        self.s3 = boto3.client(\n",
    "            's3', \n",
    "            aws_access_key_id=access_key_id, \n",
    "            aws_secret_access_key=secret_access_key,\n",
    "            aws_session_token=session_token,\n",
    "        )\n",
    "        \n",
    "    def __fix_path_prefix(self, path_prefix):\n",
    "        if \"/home/ftp\" in path_prefix:\n",
    "            datalake_dir = naas_python.secret.get(\"ABI_DATALAKE_DIR\").value\n",
    "            path_prefix = path_prefix.replace(f\"{datalake_dir}/\", \"\")\n",
    "        return path_prefix\n",
    "        \n",
    "    def pload(\n",
    "        self,\n",
    "        path_prefix,\n",
    "        file_name\n",
    "    ):\n",
    "        # Init path\n",
    "        file_path = os.path.join(self.bucket_prefix, self.__fix_path_prefix(path_prefix), f'{file_name}.pickle')\n",
    "        try:\n",
    "            obj = self.s3.get_object(Bucket=self.bucket_name, Key=file_path)\n",
    "            bytestream = BytesIO(obj['Body'].read())\n",
    "            return pickle.load(bytestream)\n",
    "        except Exception as e:\n",
    "            return None\n",
    "        return pickle_data\n",
    "\n",
    "    def pdump(\n",
    "        self,\n",
    "        path_prefix,\n",
    "        object_to_dump,\n",
    "        file_name,\n",
    "    ):\n",
    "        # Init paths\n",
    "        file_path = os.path.join(self.bucket_prefix, self.__fix_path_prefix(path_prefix), f'{file_name}.pickle')\n",
    "        histo_path = os.path.join(self.bucket_prefix, self.__fix_path_prefix(path_prefix), f'{datetime.now().strftime(\"%Y%m%d%H%M%S\")}_{file_name}.pickle')\n",
    "        \n",
    "        # Save pickle files\n",
    "        pickle_byte_obj = BytesIO()\n",
    "        pickle.dump(object_to_dump, pickle_byte_obj)\n",
    "        pickle_byte_obj.seek(0)\n",
    "        self.s3.put_object(Bucket=self.bucket_name, Key=file_path, Body=pickle_byte_obj)\n",
    "        self.s3.put_object(Bucket=self.bucket_name, Key=histo_path, Body=pickle_byte_obj)\n",
    "        \n",
    "    def save_data(\n",
    "        self,\n",
    "        obj,\n",
    "        dl_dir,\n",
    "        entity_name,\n",
    "        file_name,\n",
    "    ):\n",
    "        # Get entity code\n",
    "        entity_code = unidecode(entity_name.lower().replace(\" \", \"_\").replace(\".\", \"\"))\n",
    "\n",
    "        # Create directory path\n",
    "        dir_path = os.path.join(dl_dir, entity_code, \"tables\", file_name)\n",
    "\n",
    "        # Save in pickle\n",
    "        self.pdump(dir_path, obj, file_name)\n",
    "        \n",
    "    def upload_file(\n",
    "        self,\n",
    "        source_path,\n",
    "        destination_path=None,\n",
    "    ):\n",
    "        file_path = self.__fix_path_prefix(source_path)\n",
    "        if destination_path is not None:\n",
    "            file_path = self.__fix_path_prefix(destination_path)\n",
    "        \n",
    "        self.s3.upload_file(source_path, self.bucket_name, os.path.join(self.bucket_prefix, file_path))\n",
    "        print(f\"✅ Object successfully uploaded: {file_path}\")\n",
    "        return file_path\n",
    "    \n",
    "    def list_objects(\n",
    "        self,\n",
    "        path_prefix=None,\n",
    "        path_pattern=None\n",
    "    ):\n",
    "        # Init\n",
    "        files = []\n",
    "        dir_path = self.bucket_prefix\n",
    "        pattern = \"*\"\n",
    "        if path_prefix is not None:\n",
    "            dir_path = os.path.join(self.bucket_prefix, self.__fix_path_prefix(path_prefix))\n",
    "        if path_pattern is not None:\n",
    "            pattern = \"\".join(self.__fix_path_prefix(path_pattern))\n",
    "        \n",
    "        # List objects\n",
    "        response = self.s3.list_objects_v2(Bucket=self.bucket_name, Prefix=dir_path + \"/\")\n",
    "        \n",
    "        # Process the response\n",
    "        if 'Contents' in response:\n",
    "            for file in response['Contents']:\n",
    "                file_name = file['Key'].split(self.bucket_prefix + \"/\")[1]\n",
    "                if file_name != '' and fnmatch.fnmatch(file_name, pattern):\n",
    "                    files.append(file_name)\n",
    "        return files\n",
    "    \n",
    "    def delete_object(self, file_name):\n",
    "        file_path = os.path.join(self.bucket_prefix, self.__fix_path_prefix(file_name))\n",
    "        self.s3.delete_object(Bucket=self.bucket_name, Key=file_path)\n",
    "        print(\"✅ Object successfully deleted!\")\n",
    "        \n",
    "# sm = StorageManager(access_key_id, secret_access_key, session_token, bucket_name, bucket_prefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
